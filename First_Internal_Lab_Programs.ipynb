{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exe1data.txt\n",
      "6.1101,17.592\n",
      "5.5277,9.1302\n",
      "8.5186,13.662\n",
      "7.0032,11.854\n",
      "5.8598,6.8233\n",
      "8.3829,11.886\n",
      "7.4764,4.3483\n",
      "8.5781,12\n",
      "6.4862,6.5987\n",
      "5.0546,3.8166\n",
      "5.7107,3.2522\n",
      "14.164,15.505\n",
      "5.734,3.1551\n",
      "8.4084,7.2258\n",
      "5.6407,0.71618\n",
      "5.3794,3.5129\n",
      "6.3654,5.3048\n",
      "5.1301,0.56077\n",
      "6.4296,3.6518\n",
      "7.0708,5.3893\n",
      "6.1891,3.1386\n",
      "20.27,21.767\n",
      "5.4901,4.263\n",
      "6.3261,5.1875\n",
      "5.5649,3.0825\n",
      "18.945,22.638\n",
      "12.828,13.501\n",
      "10.957,7.0467\n",
      "13.176,14.692\n",
      "22.203,24.147\n",
      "5.2524,-1.22\n",
      "6.5894,5.9966\n",
      "9.2482,12.134\n",
      "5.8918,1.8495\n",
      "8.2111,6.5426\n",
      "7.9334,4.5623\n",
      "8.0959,4.1164\n",
      "5.6063,3.3928\n",
      "12.836,10.117\n",
      "6.3534,5.4974\n",
      "5.4069,0.55657\n",
      "6.8825,3.9115\n",
      "11.708,5.3854\n",
      "5.7737,2.4406\n",
      "7.8247,6.7318\n",
      "7.0931,1.0463\n",
      "5.0702,5.1337\n",
      "5.8014,1.844\n",
      "11.7,8.0043\n",
      "5.5416,1.0179\n",
      "7.5402,6.7504\n",
      "5.3077,1.8396\n",
      "7.4239,4.2885\n",
      "7.6031,4.9981\n",
      "6.3328,1.4233\n",
      "6.3589,-1.4211\n",
      "6.2742,2.4756\n",
      "5.6397,4.6042\n",
      "9.3102,3.9624\n",
      "9.4536,5.4141\n",
      "8.8254,5.1694\n",
      "5.1793,-0.74279\n",
      "21.279,17.929\n",
      "14.908,12.054\n",
      "18.959,17.054\n",
      "7.2182,4.8852\n",
      "8.2951,5.7442\n",
      "10.236,7.7754\n",
      "5.4994,1.0173\n",
      "20.341,20.992\n",
      "10.136,6.6799\n",
      "7.3345,4.0259\n",
      "6.0062,1.2784\n",
      "7.2259,3.3411\n",
      "5.0269,-2.6807\n",
      "6.5479,0.29678\n",
      "7.5386,3.8845\n",
      "5.0365,5.7014\n",
      "10.274,6.7526\n",
      "5.1077,2.0576\n",
      "5.7292,0.47953\n",
      "5.1884,0.20421\n",
      "6.3557,0.67861\n",
      "9.7687,7.5435\n",
      "6.5159,5.3436\n",
      "8.5172,4.2415\n",
      "9.1802,6.7981\n",
      "6.002,0.92695\n",
      "5.5204,0.152\n",
      "5.0594,2.8214\n",
      "5.7077,1.8451\n",
      "7.6366,4.2959\n",
      "5.8707,7.2029\n",
      "5.3054,1.9869\n",
      "8.2934,0.14454\n",
      "13.394,9.0551\n",
      "5.4369,0.61705\n",
      "\n",
      "file1.txt\n",
      "Hello world!!!\n",
      "file2 (1).txt\n",
      "Principles of Data Science\n",
      "file3.txt\n",
      "Welcome\n"
     ]
    }
   ],
   "source": [
    "#program to read multiple files from same folder\n",
    "import os\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith(\".txt\"):\n",
    "        file_path = os.path.join(path, file)\n",
    "        print(file)\n",
    "        with open(file_path, 'r') as f:\n",
    "            print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\Sample\\Sample_subfolder1\n",
      "file1.txt\n",
      "Hello world!!!\n",
      "F:\\Sample\\Sample_subfolder1\n",
      "file2 (1).txt\n",
      "Principles of Data Science\n",
      "F:\\Sample\\Sample_subfolder1\n",
      "file3.txt\n",
      "Welcome\n",
      "F:\\Sample\\Sample_subfolder2\n",
      "fruit_data.txt\n",
      "fruit_label\tfruit_name\tfruit_subtype\tmass\twidth\theight\tcolor_score\n",
      "1\tapple\tgranny_smith\t193\t10.4\t8.3\t1.55\n",
      "1\tapple\tgranny_smith\t181\t9.0\t7.8\t1.59\n",
      "1\tapple\tgranny_smith\t177\t8.4\t8.2\t1.60\n",
      "2\tmandarin\tmandarin\t87 \t7.2\t5.7\t1.80\n",
      "2\tmandarin\tmandarin\t85 \t7.0\t5.6\t1.79\n",
      "2\tmandarin\tmandarin\t81 \t6.8\t5.3\t1.77\n",
      "2\tmandarin\tmandarin\t81 \t5.9 \t4.3\t0.81\n",
      "2\tmandarin\tmandarin\t76\t6.8\t5.0\t1.81\n",
      "1\tapple\tbraeburn\t187\t8.1\t8.8\t1.92\n",
      "1\tapple\tbraeburn\t272\t8.4\t9.0\t2.89\n",
      "1\tapple\tbraeburn\t266\t7.9\t9.3\t2.93\n",
      "1\tapple\tbraeburn\t272\t9.1\t9.6\t2.92\n",
      "1\tapple\tbraeburn\t254\t9.0\t8.1\t2.88\n",
      "F:\\Sample\\Sample_subfolder3\n",
      "file11.txt\n",
      "Matplotlib is an amazing visualization library in Python for 2D plots of arrays. \n",
      "It was introduced by John Hunter in the year 2002. \n",
      "Matplotlib consists of several plots like line, bar, scatter, histogram, etc.\n",
      "F:\\Sample\\Sample_subfolder3\n",
      "sample.txt\n",
      "Python is a dynamic, high-level, free open source, and interpreted programming language. It supports object-oriented programming as well as procedural-oriented programming. In Python, we donâ€™t need to declare the type of variable because it is a dynamically typed language. For example, x = 10 Here, x can be anything such as String, int, etc. In this article we will see what characteristics describe the python programming language\n",
      "\n",
      "Features in Python\n",
      "In this section we will see what are the features of Python programming language:\n",
      "\n",
      "1. Free and Open Source\n",
      "Python language is freely available at the official website and you can download it from the given download link below click on the Download Python keyword. Download Python Since it is open-source, this means that source code is also available to the public. So you can download it, use it as well as share it. \n",
      "\n",
      "2. Easy to code\n",
      "Python is a high-level programming language. Python is very easy to learn the language as compared to other languages like C, C#, Javascript, Java, etc. It is very easy to code in the Python language and anybody can learn Python basics in a few hours or days. It is also a developer-friendly language. \n",
      "\n",
      "3. Easy to Read\n",
      "As you will see, learning Python is quite simple. As was already established, Pythonâ€™s syntax is really straightforward. The code block is defined by the indentations rather than by semicolons or brackets.\n",
      "\n",
      "4. Object-Oriented Language\n",
      "One of the key features of Python is Object-Oriented programming. Python supports object-oriented language and concepts of classes, object encapsulation, etc. \n",
      "\n",
      "5. GUI Programming Support\n",
      "Graphical User interfaces can be made using a module such as PyQt5, PyQt4, wxPython, or Tk in Python. PyQt5 is the most popular option for creating graphical apps with Python.\n",
      "\n",
      "6. High-Level Language\n",
      "Python is a high-level language. When we write programs in Python, we do not need to remember the system architecture, nor do we need to manage the memory.\n",
      "\n",
      "7. Large Community Support\n",
      "Python has gained popularity over the years. Our questions are constantly answered by the enormous StackOverflow community. These websites have already provided answers to many questions about Python, so Python users can consult them as needed.\n",
      "\n",
      "8. Easy to Debug\n",
      "Excellent information for mistake tracing. You will be able to quickly identify and correct the majority of your programâ€™s issues once you understand how to interpret Pythonâ€™s error traces. Simply by glancing at the code, you can determine what it is designed to perform.\n",
      "\n",
      "9. Python is a Portable language\n",
      "Python language is also a portable language. For example, if we have Python code for Windows and if we want to run this code on other platforms such as Linux, Unix, and Mac then we do not need to change it, we can run this code on any platform.\n",
      "\n",
      "10. Python is an Integrated language\n",
      "Python is also an Integrated language because we can easily integrate Python with other languages like C, C++, etc. \n",
      "\n",
      "11. Interpreted Language: \n",
      "Python is an Interpreted Language because Python code is executed line by line at a time. like other languages C, C++, Java, etc. there is no need to compile Python code this makes it easier to debug our code. The source code of Python is converted into an immediate form called bytecode.\n",
      "\n",
      "12. Large Standard Library \n",
      "Python has a large standard library that provides a rich set of modules and functions so you do not have to write your own code for every single thing. There are many libraries present in Python such as regular expressions, unit-testing, web browsers, etc.\n",
      "\n",
      "13. Dynamically Typed Language\n",
      "Python is a dynamically-typed language. That means the type (for example- int, double, long, etc.) for a variable is decided at run time not in advance because of this feature we donâ€™t need to specify the type of variable.\n",
      "\n",
      "14. Frontend and backend development\n",
      "With a new project py script, you can run and write Python codes in HTML with the help of some simple tags <py-script>, <py-env>, etc. This will help you do frontend development work in Python like javascript. Backend is the strong forte of Python itâ€™s extensively used for this work cause of its frameworks like Django and Flask.\n",
      "\n",
      "15. Allocating Memory Dynamically\n",
      "In Python, the variable data type does not need to be specified. The memory is automatically allocated to a variable at runtime when it is given a value. Developers do not need to write int y = 18 if the integer value 15 is set to y. You may just type y=18.\n"
     ]
    }
   ],
   "source": [
    "#program to read multiple files from multple folders\n",
    "\n",
    "import os\n",
    "\n",
    "def read_text_files_from_folders(root_folder):\n",
    "    for folder_name, subfolders, filenames in os.walk(root_folder):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.txt'):\n",
    "                file_path = os.path.join(folder_name, filename)\n",
    "                try:\n",
    "                    with open(file_path, 'r') as file:\n",
    "                \n",
    "                        print(folder_name)\n",
    "                        print(filename)\n",
    "                        \n",
    "                        print(file.read())\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading file {file_path}: {e}\")\n",
    "    return texts\n",
    "\n",
    "root_folder = \"F:\\Sample\"\n",
    "texts = read_text_files_from_folders(root_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter number of elements :: 7\n",
      "Enter a number :: 4\n",
      "Enter a number :: 1\n",
      "Enter a number :: 1\n",
      "Enter a number :: 3\n",
      "Enter a number :: 6\n",
      "Enter a number :: 3\n",
      "Enter a number :: 8\n",
      "List elements are ::  [4, 1, 1, 3, 6, 3, 8]\n",
      "Mean ::  3.7142857142857144\n",
      "Sorted list elements are ::  [1, 1, 3, 3, 4, 6, 8]\n",
      "Median ::  3\n",
      "Mode ::  [1, 3]\n"
     ]
    }
   ],
   "source": [
    "#mean, mdian and mode without using built-in\n",
    "\n",
    "def find_mean(list1):\n",
    "    total = 0\n",
    "    for ele in list1:\n",
    "        total += ele\n",
    "    mean = total / n\n",
    "    print(\"List elements are :: \",list1)\n",
    "    print(\"Mean :: \",mean)\n",
    "    \n",
    "def find_median(list1):\n",
    "    list1.sort()\n",
    "    print(\"Sorted list elements are :: \",list1)\n",
    "    if n % 2 == 0: \n",
    "        median = (list1[n // 2] + list1[n // 2 - 1]) / 2\n",
    "    else:\n",
    "        median = list1[n // 2]\n",
    "    print(\"Median :: \", median)\n",
    "    \n",
    "def find_mode(list1):\n",
    "    unq_list = []\n",
    "    non_unq_list = []\n",
    "    for ele in list1:\n",
    "        if ele not in unq_list:\n",
    "            unq_list.append(ele)\n",
    "        else:\n",
    "            non_unq_list.append(ele)\n",
    "    max_count = 0\n",
    "    mode_list = []\n",
    "    for ele in unq_list:\n",
    "        currentCount = non_unq_list.count(ele)\n",
    "        if currentCount > max_count:\n",
    "            max_count = currentCount\n",
    "            mode_list = [ele]\n",
    "        elif currentCount == max_count:\n",
    "            mode_list.append(ele)\n",
    "    print(\"Mode :: \", mode_list)\n",
    "    \n",
    "\n",
    "list1 = []\n",
    "n = int(input(\"Enter number of elements :: \"))\n",
    "for i in range(n) :\n",
    "    list1.append(int(input(\"Enter a number :: \")))\n",
    "    \n",
    "find_mean(list1)\n",
    "find_median(list1)\n",
    "find_mode(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of elements ::7\n",
      "Enter the elements ::4\n",
      "Enter the elements ::1\n",
      "Enter the elements ::7\n",
      "Enter the elements ::9\n",
      "Enter the elements ::3\n",
      "Enter the elements ::11\n",
      "Enter the elements ::6\n",
      "List elements are\n",
      " [4, 1, 7, 9, 3, 11, 6]\n",
      "The range(without built-in)::  10\n",
      "The range(with built-in)::  10\n",
      "The variance(without built-in)::  10.408163265306124\n",
      "The variance(with built-in)::  10.408163265306124\n",
      "The standard deviation(without built-in)::  3.2261685116103473\n",
      "The standard deviation(with built-in)::  3.2261685116103473\n",
      "Interquartile Range(without built-in function): 5.5\n",
      "IQR(with built-in function): 4.5\n"
     ]
    }
   ],
   "source": [
    "#python program to find range, variance, standard deviation and interquartile range\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import stats\n",
    "\n",
    "def find_range(list1):\n",
    "    maxElement = minElement = list1[0]\n",
    "    for ele in list1:\n",
    "        if ele > maxElement:\n",
    "            maxElement = ele\n",
    "        if ele < minElement:\n",
    "            minElement = ele\n",
    "    rangeValue = maxElement - minElement\n",
    "    return rangeValue\n",
    "\n",
    "def find_variance(list1):\n",
    "    total = 0\n",
    "    for ele in list1:\n",
    "        total += ele\n",
    "    mean = total / len(list1)\n",
    "    sumValue = 0\n",
    "    for i in list1:\n",
    "        sumValue += (i - mean) ** 2\n",
    "    variance = sumValue / len(list1)\n",
    "    return variance\n",
    "\n",
    "def find_sd(list1):\n",
    "    sd = math.sqrt(find_variance(list1))\n",
    "    return sd\n",
    "\n",
    "def calculate_iqr(data):\n",
    "    # Sort the data\n",
    "    data = sorted(data)\n",
    "    \n",
    "    # Find the median\n",
    "    def median(lst):\n",
    "        n = len(lst)\n",
    "        mid = n // 2\n",
    "        if n % 2 == 0:\n",
    "            return (lst[mid - 1] + lst[mid]) / 2.0\n",
    "        else:\n",
    "            return lst[mid]\n",
    "    \n",
    "    # Split the data into lower and upper halves\n",
    "    n = len(data)\n",
    "    mid = n // 2\n",
    "    if n % 2 == 0:\n",
    "        lower_half = data[:mid]\n",
    "        upper_half = data[mid:]\n",
    "    else:\n",
    "        lower_half = data[:mid + 1] \n",
    "        upper_half = data[mid + 1:]\n",
    "    \n",
    "    # Calculate Q1 and Q3\n",
    "    Q1 = median(lower_half)\n",
    "    Q3 = median(upper_half)\n",
    "    \n",
    "    # Calculate IQR\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    return IQR\n",
    "\n",
    "list1 = []\n",
    "n=int(input(\"Enter the number of elements ::\"))\n",
    "for i in range(n):\n",
    "    ele = int(input(\"Enter the elements ::\"))\n",
    "    list1.append(ele)\n",
    "print(\"List elements are\\n\", list1) \n",
    "\n",
    "\n",
    "\n",
    "print(\"The range(without built-in):: \", find_range(list1))\n",
    "\n",
    "maximum = np.max(list1)\n",
    "minimum = np.min(list1)\n",
    "range_value = maximum - minimum\n",
    "print(\"The range(with built-in):: \", range_value)\n",
    "\n",
    "print(\"The variance(without built-in):: \", find_variance(list1))\n",
    "\n",
    "print(\"The variance(with built-in):: \", np.var(list1))\n",
    "\n",
    "print(\"The standard deviation(without built-in):: \", find_sd(list1))\n",
    "\n",
    "print(\"The standard deviation(with built-in):: \", np.std(list1))\n",
    "\n",
    "iqr = calculate_iqr(list1)\n",
    "print(\"Interquartile Range(without built-in function):\", iqr)\n",
    "\n",
    "IQR = stats.iqr(list1, interpolation='midpoint')\n",
    "print(\"IQR(with built-in function):\", IQR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing using built-in functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Using cached spacy-3.7.4-cp38-cp38-win_amd64.whl (12.5 MB)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script weasel.exe is installed in 'C:\\Users\\yashushetty\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script spacy.exe is installed in 'C:\\Users\\yashushetty\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: numpy>=1.15.0; python_version < \"3.9\" in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (1.18.5)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Using cached srsly-2.4.8-cp38-cp38-win_amd64.whl (483 kB)\n",
      "Collecting thinc<8.3.0,>=8.2.2\n",
      "  Using cached thinc-8.2.3-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.24.0)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.11.2)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Using cached murmurhash-1.0.10-cp38-cp38-win_amd64.whl (25 kB)\n",
      "Collecting weasel<0.4.0,>=0.1.0\n",
      "  Using cached weasel-0.3.4-py3-none-any.whl (50 kB)\n",
      "Collecting typer<0.10.0,>=0.3.0\n",
      "  Using cached typer-0.9.4-py3-none-any.whl (45 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Using cached cymem-2.0.8-cp38-cp38-win_amd64.whl (39 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Using cached preshed-3.0.9-cp38-cp38-win_amd64.whl (122 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (4.47.0)\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Using cached wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Using cached langcodes-3.4.0-py3-none-any.whl (182 kB)\n",
      "Collecting smart-open<7.0.0,>=5.2.1\n",
      "  Using cached smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (20.4)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (49.2.0.post20200714)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4\n",
      "  Using cached pydantic-2.7.1-py3-none-any.whl (409 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Using cached confection-0.1.4-py3-none-any.whl (35 kB)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Using cached blis-0.7.11-cp38-cp38-win_amd64.whl (6.6 MB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.9)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0\n",
      "  Using cached cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "Collecting typing-extensions>=3.7.4.3\n",
      "  Using cached typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (7.1.2)\n",
      "Collecting colorama>=0.4.6; sys_platform == \"win32\" and python_version >= \"3.7\"\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Collecting language-data>=1.2\n",
      "  Using cached language_data-1.2.0-py3-none-any.whl (5.4 MB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (1.15.0)\n",
      "Collecting pydantic-core==2.18.2\n",
      "  Using cached pydantic_core-2.18.2-cp38-none-win_amd64.whl (1.9 MB)\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Collecting marisa-trie>=0.7.7\n",
      "  Using cached marisa_trie-1.1.1-cp38-cp38-win_amd64.whl (152 kB)\n",
      "Installing collected packages: spacy-legacy, spacy-loggers, catalogue, srsly, murmurhash, cymem, preshed, colorama, wasabi, typing-extensions, pydantic-core, annotated-types, pydantic, confection, blis, thinc, cloudpathlib, typer, smart-open, weasel, marisa-trie, language-data, langcodes, spacy\n",
      "Successfully installed annotated-types-0.6.0 blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.16.0 colorama-0.4.6 confection-0.1.4 cymem-2.0.8 langcodes-3.4.0 language-data-1.2.0 marisa-trie-1.1.1 murmurhash-1.0.10 preshed-3.0.9 pydantic-2.7.1 pydantic-core-2.18.2 smart-open-6.4.0 spacy-3.7.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.3 typer-0.9.4 typing-extensions-4.11.0 wasabi-1.1.2 weasel-0.3.4\n"
     ]
    }
   ],
   "source": [
    "!pip install --user spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting num2words\n",
      "  Downloading num2words-0.5.13-py3-none-any.whl (143 kB)\n",
      "Collecting docopt>=0.6.2\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13709 sha256=426ffdacda627a2f56f677bead31978b6c8fa3278792a91ac9ef1c2d4692643c\n",
      "  Stored in directory: c:\\users\\yashushetty\\appdata\\local\\pip\\cache\\wheels\\56\\ea\\58\\ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
      "Successfully built docopt\n",
      "Installing collected packages: docopt, num2words\n",
      "Successfully installed docopt-0.6.2 num2words-0.5.13\n",
      "Collecting num2words\n",
      "  Using cached num2words-0.5.13-py3-none-any.whl (143 kB)\n",
      "Collecting docopt>=0.6.2\n",
      "  Using cached docopt-0.6.2.tar.gz (25 kB)\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13709 sha256=426ffdacda627a2f56f677bead31978b6c8fa3278792a91ac9ef1c2d4692643c\n",
      "  Stored in directory: c:\\users\\yashushetty\\appdata\\local\\pip\\cache\\wheels\\56\\ea\\58\\ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
      "Successfully built docopt\n",
      "Installing collected packages: docopt, num2words\n",
      "Successfully installed docopt-0.6.2 num2words-0.5.13\n"
     ]
    }
   ],
   "source": [
    "!pip install --user num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting contractions\n",
      "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting textsearch>=0.0.21\n",
      "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting pyahocorasick\n",
      "  Downloading pyahocorasick-2.1.0-cp38-cp38-win_amd64.whl (39 kB)\n",
      "Collecting anyascii\n",
      "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
      "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
      "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n"
     ]
    }
   ],
   "source": [
    "!pip install --user contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "  Downloading emoji-2.11.1-py2.py3-none-any.whl (433 kB)\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-2.11.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --user emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting demoji\n",
      "  Downloading demoji-1.1.0-py3-none-any.whl (42 kB)\n",
      "Installing collected packages: demoji\n",
      "Successfully installed demoji-1.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script demoji.exe is installed in 'C:\\Users\\yashushetty\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install --user demoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-54a3b2b5568b>:18: FutureWarning: The demoji.download_codes attribute is deprecated and will be removed from demoji in a future version. It is an unused attribute as emoji codes are now distributed directly with the demoji package.\n",
      "  demoji.download_codes()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from num2words import num2words\n",
    "import string\n",
    "import contractions\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import regex\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "import demoji\n",
    "import emoji\n",
    "from sklearn.metrics import f1_score\n",
    "demoji.download_codes()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\yashushetty\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\yashushetty\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Error loading whitespace: Package 'whitespace' not found\n",
      "[nltk_data]     in index\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\yashushetty\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\yashushetty\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('whitespace')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Training.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1382343793341575169</td>\n",
       "      <td>@IrvineWelsh I don’t know about you Irvine but...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1377631738692796417</td>\n",
       "      <td>I bet money if i went n took a covid test righ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1386448010029240326</td>\n",
       "      <td>@JamesMelville My wife received a POSITIVE Cov...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1361342676340211717</td>\n",
       "      <td>Out of the 180,000+ people who have had the tw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1386757983254765569</td>\n",
       "      <td>My whole family is sick af and here I am now i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1382001700853125122</td>\n",
       "      <td>@renfrew1962 @PeakePolly @J_Deliciouso I'm not...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1383272654212272136</td>\n",
       "      <td>Test came back positive, no surprise. I have c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1374479299047084035</td>\n",
       "      <td>My Pawpaw has been in the hospital a few days....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1354020426620547072</td>\n",
       "      <td>@MattHancock 4 people I know had covid and rec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1362671045136809985</td>\n",
       "      <td>I’m going to sound like I have lost my marbles...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                               text  \\\n",
       "0  1382343793341575169  @IrvineWelsh I don’t know about you Irvine but...   \n",
       "1  1377631738692796417  I bet money if i went n took a covid test righ...   \n",
       "2  1386448010029240326  @JamesMelville My wife received a POSITIVE Cov...   \n",
       "3  1361342676340211717  Out of the 180,000+ people who have had the tw...   \n",
       "4  1386757983254765569  My whole family is sick af and here I am now i...   \n",
       "5  1382001700853125122  @renfrew1962 @PeakePolly @J_Deliciouso I'm not...   \n",
       "6  1383272654212272136  Test came back positive, no surprise. I have c...   \n",
       "7  1374479299047084035  My Pawpaw has been in the hospital a few days....   \n",
       "8  1354020426620547072  @MattHancock 4 people I know had covid and rec...   \n",
       "9  1362671045136809985  I’m going to sound like I have lost my marbles...   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "5      0  \n",
       "6      1  \n",
       "7      0  \n",
       "8      0  \n",
       "9      1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6266\n",
       "1    1334\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps =PorterStemmer()\n",
    "lemmatiser = WordNetLemmatizer()\n",
    "english_stopwords = stopwords.words('english')\n",
    "exclude = set(string.punctuation)\n",
    "def preprocess(text):\n",
    "    #text=demoji.findall(df['Text'])\n",
    "    text = contractions.fix(text.lower(), slang=True)\n",
    "    text = re.sub(r'\\d+', lambda x: num2words(int(x.group(0))), text)\n",
    "    #text= re.sub(r'\\d+', '', text)\n",
    "    text=re.sub(r'$', '', text)\n",
    "    text= re.sub(r'’','', text )\n",
    "    text=re.sub('<.*?>','',text)\n",
    "    text=re.sub(r'http\\S+', '', text)\n",
    "    #text=emoji.demojize(text, delimiters=(\" \", \" \"))\n",
    "    text = ''.join(ch for ch in text if ch not in exclude)\n",
    "    tokens = word_tokenize(text)\n",
    "    #print(\"Tokens:\", tokens)\n",
    "    text = [t for t in tokens if t not in english_stopwords]\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "#import demoji\n",
    "#demoji.download_codes()\n",
    "def emo(text):\n",
    "    temp=emoji.demojize(text,delimiters=(\" \",\" \"))\n",
    "    temp=temp.replace(\"_\",\"  \")\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['emo']=data[\"text\"].apply(lambda x:emo(x))\n",
    "data[\"clean_text\"]=data['emo'].apply(lambda X: preprocess(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>emo</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1382343793341575169</td>\n",
       "      <td>@IrvineWelsh I don’t know about you Irvine but...</td>\n",
       "      <td>0</td>\n",
       "      <td>@IrvineWelsh I don’t know about you Irvine but...</td>\n",
       "      <td>irvinewelsh know irvine keep told covid exist ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1377631738692796417</td>\n",
       "      <td>I bet money if i went n took a covid test righ...</td>\n",
       "      <td>0</td>\n",
       "      <td>I bet money if i went n took a covid test righ...</td>\n",
       "      <td>bet money went n took covid test right going t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1386448010029240326</td>\n",
       "      <td>@JamesMelville My wife received a POSITIVE Cov...</td>\n",
       "      <td>0</td>\n",
       "      <td>@JamesMelville My wife received a POSITIVE Cov...</td>\n",
       "      <td>jamesmelville wife received positive covid tes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1361342676340211717</td>\n",
       "      <td>Out of the 180,000+ people who have had the tw...</td>\n",
       "      <td>0</td>\n",
       "      <td>Out of the 180,000+ people who have had the tw...</td>\n",
       "      <td>one hundred eightyzero people two vaccine shot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1386757983254765569</td>\n",
       "      <td>My whole family is sick af and here I am now i...</td>\n",
       "      <td>0</td>\n",
       "      <td>My whole family is sick af and here I am now i...</td>\n",
       "      <td>whole family sick af hospital heart palpitatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                               text  \\\n",
       "0  1382343793341575169  @IrvineWelsh I don’t know about you Irvine but...   \n",
       "1  1377631738692796417  I bet money if i went n took a covid test righ...   \n",
       "2  1386448010029240326  @JamesMelville My wife received a POSITIVE Cov...   \n",
       "3  1361342676340211717  Out of the 180,000+ people who have had the tw...   \n",
       "4  1386757983254765569  My whole family is sick af and here I am now i...   \n",
       "\n",
       "   label                                                emo  \\\n",
       "0      0  @IrvineWelsh I don’t know about you Irvine but...   \n",
       "1      0  I bet money if i went n took a covid test righ...   \n",
       "2      0  @JamesMelville My wife received a POSITIVE Cov...   \n",
       "3      0  Out of the 180,000+ people who have had the tw...   \n",
       "4      0  My whole family is sick af and here I am now i...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  irvinewelsh know irvine keep told covid exist ...  \n",
       "1  bet money went n took covid test right going t...  \n",
       "2  jamesmelville wife received positive covid tes...  \n",
       "3  one hundred eightyzero people two vaccine shot...  \n",
       "4  whole family sick af hospital heart palpitatio...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>emo</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7570</th>\n",
       "      <td>1375556191900798982</td>\n",
       "      <td>In 12 months, I only know of 3 people who test...</td>\n",
       "      <td>0</td>\n",
       "      <td>In 12 months, I only know of 3 people who test...</td>\n",
       "      <td>twelve months know three people tested positiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7571</th>\n",
       "      <td>1386424325268557832</td>\n",
       "      <td>@anet2111 I live in a state with the populatio...</td>\n",
       "      <td>0</td>\n",
       "      <td>@anet2111 I live in a state with the populatio...</td>\n",
       "      <td>anettwo thousand one hundred eleven live state...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7572</th>\n",
       "      <td>1381642657429082112</td>\n",
       "      <td>Yupppp, I've seen a few stroke patients in the...</td>\n",
       "      <td>0</td>\n",
       "      <td>Yupppp, I've seen a few stroke patients in the...</td>\n",
       "      <td>yupppp seen stroke patients fortys fiftys reha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7573</th>\n",
       "      <td>1377644044197752837</td>\n",
       "      <td>@EvelKneidel Actually my gym costs $10 a month...</td>\n",
       "      <td>0</td>\n",
       "      <td>@EvelKneidel Actually my gym costs $10 a month...</td>\n",
       "      <td>evelkneidel actually gym costs ten month way b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7574</th>\n",
       "      <td>1375572937739210754</td>\n",
       "      <td>@annabkrr Got my second shot &amp;amp; I continue ...</td>\n",
       "      <td>0</td>\n",
       "      <td>@annabkrr Got my second shot &amp;amp; I continue ...</td>\n",
       "      <td>annabkrr got second shot amp continue wear mas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7575</th>\n",
       "      <td>1387648123246350338</td>\n",
       "      <td>Went to hospital yesterday because I had some ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Went to hospital yesterday because I had some ...</td>\n",
       "      <td>went hospital yesterday chest pain got chest x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7576</th>\n",
       "      <td>1387906108514136066</td>\n",
       "      <td>Well... I got my second Pfizer dose two weeken...</td>\n",
       "      <td>0</td>\n",
       "      <td>Well... I got my second Pfizer dose two weeken...</td>\n",
       "      <td>well got second pfizer dose two weekends ago r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7577</th>\n",
       "      <td>1304095108862586880</td>\n",
       "      <td>last night, after reading about the 46-year-ol...</td>\n",
       "      <td>0</td>\n",
       "      <td>last night, after reading about the 46-year-ol...</td>\n",
       "      <td>last night reading fortysixyearold woman diagn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7578</th>\n",
       "      <td>1373826228105383937</td>\n",
       "      <td>And a few weeks ago, I had COVID (very mild th...</td>\n",
       "      <td>1</td>\n",
       "      <td>And a few weeks ago, I had COVID (very mild th...</td>\n",
       "      <td>weeks ago covid mild thankfully wife found got...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7579</th>\n",
       "      <td>1349069842377187328</td>\n",
       "      <td>Seeing all these Members of Congress (who’ve a...</td>\n",
       "      <td>0</td>\n",
       "      <td>Seeing all these Members of Congress (who’ve a...</td>\n",
       "      <td>seeing members congress received first dose va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7580</th>\n",
       "      <td>1339654898904752128</td>\n",
       "      <td>I am scheduled to have COVID vaccine Monday. C...</td>\n",
       "      <td>0</td>\n",
       "      <td>I am scheduled to have COVID vaccine Monday. C...</td>\n",
       "      <td>scheduled covid vaccine monday currently round...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7581</th>\n",
       "      <td>1374160581641527302</td>\n",
       "      <td>@SheriLoCascio Be honest, will they be wearing...</td>\n",
       "      <td>0</td>\n",
       "      <td>@SheriLoCascio Be honest, will they be wearing...</td>\n",
       "      <td>sherilocascio honest wearing mask whole time i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7582</th>\n",
       "      <td>1375207369601257472</td>\n",
       "      <td>I got in close contact with a positive covid p...</td>\n",
       "      <td>0</td>\n",
       "      <td>I got in close contact with a positive covid p...</td>\n",
       "      <td>got close contact positive covid patient swab ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7583</th>\n",
       "      <td>1373658117171507205</td>\n",
       "      <td>@Richard_Norfolk @jeremyhead i honestly don't ...</td>\n",
       "      <td>0</td>\n",
       "      <td>@Richard  Norfolk @jeremyhead i honestly don't...</td>\n",
       "      <td>richard norfolk jeremyhead honestly know would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7584</th>\n",
       "      <td>1372713568660033541</td>\n",
       "      <td>The patient in ICU next to my husband died tod...</td>\n",
       "      <td>0</td>\n",
       "      <td>The patient in ICU next to my husband died tod...</td>\n",
       "      <td>patient icu next husband died today sad day fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7585</th>\n",
       "      <td>1382837701536227330</td>\n",
       "      <td>@Being_Melody My husband was sick after the fi...</td>\n",
       "      <td>0</td>\n",
       "      <td>@Being  Melody My husband was sick after the f...</td>\n",
       "      <td>melody husband sick first shot think covid jan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7586</th>\n",
       "      <td>1376381344775876610</td>\n",
       "      <td>ON TOP of making me WORK tested positive for C...</td>\n",
       "      <td>1</td>\n",
       "      <td>ON TOP of making me WORK tested positive for C...</td>\n",
       "      <td>top making work tested positive covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7587</th>\n",
       "      <td>1374910936356638725</td>\n",
       "      <td>@Clarja_wewon 1st shot: arm slightly sore duri...</td>\n",
       "      <td>0</td>\n",
       "      <td>@Clarja  wewon 1st shot: arm slightly sore dur...</td>\n",
       "      <td>clarja wewon onest shot arm slightly sore firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7588</th>\n",
       "      <td>1353400480056172544</td>\n",
       "      <td>If you're diagnosed with covid they send you h...</td>\n",
       "      <td>0</td>\n",
       "      <td>If you're diagnosed with covid they send you h...</td>\n",
       "      <td>diagnosed covid send home without medication t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7589</th>\n",
       "      <td>1388623228030144513</td>\n",
       "      <td>i really don’t trust the statistics they put o...</td>\n",
       "      <td>1</td>\n",
       "      <td>i really don’t trust the statistics they put o...</td>\n",
       "      <td>really trust statistics put covid went er told...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7590</th>\n",
       "      <td>1373904450126032896</td>\n",
       "      <td>If I had the COVID vaccine 72 hours before a P...</td>\n",
       "      <td>0</td>\n",
       "      <td>If I had the COVID vaccine 72 hours before a P...</td>\n",
       "      <td>covid vaccine seventytwo hours pcr test chance...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7591</th>\n",
       "      <td>1386302260414664708</td>\n",
       "      <td>Goodmorning everyone. I apologize for the time...</td>\n",
       "      <td>1</td>\n",
       "      <td>Goodmorning everyone. I apologize for the time...</td>\n",
       "      <td>goodmorning everyone apologize time away recen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7592</th>\n",
       "      <td>1369334430582575109</td>\n",
       "      <td>A 92yo lady I used to help look after has had ...</td>\n",
       "      <td>0</td>\n",
       "      <td>A 92yo lady I used to help look after has had ...</td>\n",
       "      <td>ninetytwoyo lady used help look covid positive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593</th>\n",
       "      <td>1381644471989895178</td>\n",
       "      <td>@CBSNews @CBSEveningNews My buddy 68 had both ...</td>\n",
       "      <td>0</td>\n",
       "      <td>@CBSNews @CBSEveningNews My buddy 68 had both ...</td>\n",
       "      <td>cbsnews cbseveningnews buddy sixtyeight shots ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7594</th>\n",
       "      <td>1377831579922366465</td>\n",
       "      <td>Damn just found out I tested positive for Covi...</td>\n",
       "      <td>1</td>\n",
       "      <td>Damn just found out I tested positive for Covi...</td>\n",
       "      <td>damn found tested positive covid earlier today...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7595</th>\n",
       "      <td>1370572921043701761</td>\n",
       "      <td>@galaflux @efb_1 @DrJekyllHJ7 @DrLeanaWen I’m ...</td>\n",
       "      <td>0</td>\n",
       "      <td>@galaflux @efb  1 @DrJekyllHJ7 @DrLeanaWen I’m...</td>\n",
       "      <td>galaflux efb one drjekyllhjseven drleanawen wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7596</th>\n",
       "      <td>1381076072129695746</td>\n",
       "      <td>@tabbattales @nursekelsey I ended up in the ho...</td>\n",
       "      <td>1</td>\n",
       "      <td>@tabbattales @nursekelsey I ended up in the ho...</td>\n",
       "      <td>tabbattales nursekelsey ended hospital fever b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7597</th>\n",
       "      <td>1378912704530935809</td>\n",
       "      <td>@UNREALJUST @recDNA @CDCgov How do you know? M...</td>\n",
       "      <td>0</td>\n",
       "      <td>@UNREALJUST @recDNA @CDCgov How do you know? M...</td>\n",
       "      <td>unrealjust recdna cdcgov know wife got market ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7598</th>\n",
       "      <td>1366144349940183042</td>\n",
       "      <td>@angela14387 no it cant be that!  I wonder wha...</td>\n",
       "      <td>0</td>\n",
       "      <td>@angela14387 no it cant be that!  I wonder wha...</td>\n",
       "      <td>angelafourteen thousand three hundred eightyse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7599</th>\n",
       "      <td>1359849897068015620</td>\n",
       "      <td>Berwick-based clinical care assistant Fiona Ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>Berwick-based clinical care assistant Fiona Ma...</td>\n",
       "      <td>berwickbased clinical care assistant fiona mat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id                                               text  \\\n",
       "7570  1375556191900798982  In 12 months, I only know of 3 people who test...   \n",
       "7571  1386424325268557832  @anet2111 I live in a state with the populatio...   \n",
       "7572  1381642657429082112  Yupppp, I've seen a few stroke patients in the...   \n",
       "7573  1377644044197752837  @EvelKneidel Actually my gym costs $10 a month...   \n",
       "7574  1375572937739210754  @annabkrr Got my second shot &amp; I continue ...   \n",
       "7575  1387648123246350338  Went to hospital yesterday because I had some ...   \n",
       "7576  1387906108514136066  Well... I got my second Pfizer dose two weeken...   \n",
       "7577  1304095108862586880  last night, after reading about the 46-year-ol...   \n",
       "7578  1373826228105383937  And a few weeks ago, I had COVID (very mild th...   \n",
       "7579  1349069842377187328  Seeing all these Members of Congress (who’ve a...   \n",
       "7580  1339654898904752128  I am scheduled to have COVID vaccine Monday. C...   \n",
       "7581  1374160581641527302  @SheriLoCascio Be honest, will they be wearing...   \n",
       "7582  1375207369601257472  I got in close contact with a positive covid p...   \n",
       "7583  1373658117171507205  @Richard_Norfolk @jeremyhead i honestly don't ...   \n",
       "7584  1372713568660033541  The patient in ICU next to my husband died tod...   \n",
       "7585  1382837701536227330  @Being_Melody My husband was sick after the fi...   \n",
       "7586  1376381344775876610  ON TOP of making me WORK tested positive for C...   \n",
       "7587  1374910936356638725  @Clarja_wewon 1st shot: arm slightly sore duri...   \n",
       "7588  1353400480056172544  If you're diagnosed with covid they send you h...   \n",
       "7589  1388623228030144513  i really don’t trust the statistics they put o...   \n",
       "7590  1373904450126032896  If I had the COVID vaccine 72 hours before a P...   \n",
       "7591  1386302260414664708  Goodmorning everyone. I apologize for the time...   \n",
       "7592  1369334430582575109  A 92yo lady I used to help look after has had ...   \n",
       "7593  1381644471989895178  @CBSNews @CBSEveningNews My buddy 68 had both ...   \n",
       "7594  1377831579922366465  Damn just found out I tested positive for Covi...   \n",
       "7595  1370572921043701761  @galaflux @efb_1 @DrJekyllHJ7 @DrLeanaWen I’m ...   \n",
       "7596  1381076072129695746  @tabbattales @nursekelsey I ended up in the ho...   \n",
       "7597  1378912704530935809  @UNREALJUST @recDNA @CDCgov How do you know? M...   \n",
       "7598  1366144349940183042  @angela14387 no it cant be that!  I wonder wha...   \n",
       "7599  1359849897068015620  Berwick-based clinical care assistant Fiona Ma...   \n",
       "\n",
       "      label                                                emo  \\\n",
       "7570      0  In 12 months, I only know of 3 people who test...   \n",
       "7571      0  @anet2111 I live in a state with the populatio...   \n",
       "7572      0  Yupppp, I've seen a few stroke patients in the...   \n",
       "7573      0  @EvelKneidel Actually my gym costs $10 a month...   \n",
       "7574      0  @annabkrr Got my second shot &amp; I continue ...   \n",
       "7575      1  Went to hospital yesterday because I had some ...   \n",
       "7576      0  Well... I got my second Pfizer dose two weeken...   \n",
       "7577      0  last night, after reading about the 46-year-ol...   \n",
       "7578      1  And a few weeks ago, I had COVID (very mild th...   \n",
       "7579      0  Seeing all these Members of Congress (who’ve a...   \n",
       "7580      0  I am scheduled to have COVID vaccine Monday. C...   \n",
       "7581      0  @SheriLoCascio Be honest, will they be wearing...   \n",
       "7582      0  I got in close contact with a positive covid p...   \n",
       "7583      0  @Richard  Norfolk @jeremyhead i honestly don't...   \n",
       "7584      0  The patient in ICU next to my husband died tod...   \n",
       "7585      0  @Being  Melody My husband was sick after the f...   \n",
       "7586      1  ON TOP of making me WORK tested positive for C...   \n",
       "7587      0  @Clarja  wewon 1st shot: arm slightly sore dur...   \n",
       "7588      0  If you're diagnosed with covid they send you h...   \n",
       "7589      1  i really don’t trust the statistics they put o...   \n",
       "7590      0  If I had the COVID vaccine 72 hours before a P...   \n",
       "7591      1  Goodmorning everyone. I apologize for the time...   \n",
       "7592      0  A 92yo lady I used to help look after has had ...   \n",
       "7593      0  @CBSNews @CBSEveningNews My buddy 68 had both ...   \n",
       "7594      1  Damn just found out I tested positive for Covi...   \n",
       "7595      0  @galaflux @efb  1 @DrJekyllHJ7 @DrLeanaWen I’m...   \n",
       "7596      1  @tabbattales @nursekelsey I ended up in the ho...   \n",
       "7597      0  @UNREALJUST @recDNA @CDCgov How do you know? M...   \n",
       "7598      0  @angela14387 no it cant be that!  I wonder wha...   \n",
       "7599      0  Berwick-based clinical care assistant Fiona Ma...   \n",
       "\n",
       "                                             clean_text  \n",
       "7570  twelve months know three people tested positiv...  \n",
       "7571  anettwo thousand one hundred eleven live state...  \n",
       "7572  yupppp seen stroke patients fortys fiftys reha...  \n",
       "7573  evelkneidel actually gym costs ten month way b...  \n",
       "7574  annabkrr got second shot amp continue wear mas...  \n",
       "7575  went hospital yesterday chest pain got chest x...  \n",
       "7576  well got second pfizer dose two weekends ago r...  \n",
       "7577  last night reading fortysixyearold woman diagn...  \n",
       "7578  weeks ago covid mild thankfully wife found got...  \n",
       "7579  seeing members congress received first dose va...  \n",
       "7580  scheduled covid vaccine monday currently round...  \n",
       "7581  sherilocascio honest wearing mask whole time i...  \n",
       "7582  got close contact positive covid patient swab ...  \n",
       "7583  richard norfolk jeremyhead honestly know would...  \n",
       "7584  patient icu next husband died today sad day fa...  \n",
       "7585  melody husband sick first shot think covid jan...  \n",
       "7586              top making work tested positive covid  \n",
       "7587  clarja wewon onest shot arm slightly sore firs...  \n",
       "7588  diagnosed covid send home without medication t...  \n",
       "7589  really trust statistics put covid went er told...  \n",
       "7590  covid vaccine seventytwo hours pcr test chance...  \n",
       "7591  goodmorning everyone apologize time away recen...  \n",
       "7592  ninetytwoyo lady used help look covid positive...  \n",
       "7593  cbsnews cbseveningnews buddy sixtyeight shots ...  \n",
       "7594  damn found tested positive covid earlier today...  \n",
       "7595  galaflux efb one drjekyllhjseven drleanawen wi...  \n",
       "7596  tabbattales nursekelsey ended hospital fever b...  \n",
       "7597  unrealjust recdna cdcgov know wife got market ...  \n",
       "7598  angelafourteen thousand three hundred eightyse...  \n",
       "7599  berwickbased clinical care assistant fiona mat...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Prprocessing without using built-in functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1382343793341575169</td>\n",
       "      <td>@IrvineWelsh I don’t know about you Irvine but...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1377631738692796417</td>\n",
       "      <td>I bet money if i went n took a covid test righ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1386448010029240326</td>\n",
       "      <td>@JamesMelville My wife received a POSITIVE Cov...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1361342676340211717</td>\n",
       "      <td>Out of the 180,000+ people who have had the tw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1386757983254765569</td>\n",
       "      <td>My whole family is sick af and here I am now i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7595</th>\n",
       "      <td>1370572921043701761</td>\n",
       "      <td>@galaflux @efb_1 @DrJekyllHJ7 @DrLeanaWen I’m ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7596</th>\n",
       "      <td>1381076072129695746</td>\n",
       "      <td>@tabbattales @nursekelsey I ended up in the ho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7597</th>\n",
       "      <td>1378912704530935809</td>\n",
       "      <td>@UNREALJUST @recDNA @CDCgov How do you know? M...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7598</th>\n",
       "      <td>1366144349940183042</td>\n",
       "      <td>@angela14387 no it cant be that!  I wonder wha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7599</th>\n",
       "      <td>1359849897068015620</td>\n",
       "      <td>Berwick-based clinical care assistant Fiona Ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7600 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id                                               text  \\\n",
       "0     1382343793341575169  @IrvineWelsh I don’t know about you Irvine but...   \n",
       "1     1377631738692796417  I bet money if i went n took a covid test righ...   \n",
       "2     1386448010029240326  @JamesMelville My wife received a POSITIVE Cov...   \n",
       "3     1361342676340211717  Out of the 180,000+ people who have had the tw...   \n",
       "4     1386757983254765569  My whole family is sick af and here I am now i...   \n",
       "...                   ...                                                ...   \n",
       "7595  1370572921043701761  @galaflux @efb_1 @DrJekyllHJ7 @DrLeanaWen I’m ...   \n",
       "7596  1381076072129695746  @tabbattales @nursekelsey I ended up in the ho...   \n",
       "7597  1378912704530935809  @UNREALJUST @recDNA @CDCgov How do you know? M...   \n",
       "7598  1366144349940183042  @angela14387 no it cant be that!  I wonder wha...   \n",
       "7599  1359849897068015620  Berwick-based clinical care assistant Fiona Ma...   \n",
       "\n",
       "      label  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "...     ...  \n",
       "7595      0  \n",
       "7596      1  \n",
       "7597      0  \n",
       "7598      0  \n",
       "7599      0  \n",
       "\n",
       "[7600 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('Training.tsv',sep='\\t')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define English stopwords\n",
    "english_stopwords = set(['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\n",
    "                         \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself',\n",
    "                         'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\n",
    "                         'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these',\n",
    "                         'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had',\n",
    "                         'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because',\n",
    "                         'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    "                         'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out',\n",
    "                         'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when',\n",
    "                         'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some',\n",
    "                         'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can',\n",
    "                         'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've',\n",
    "                         'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\",\n",
    "                         'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn',\n",
    "                         \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\",\n",
    "                         'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"])\n",
    "\n",
    "\n",
    "def normalize_apostrophes(text):\n",
    "    # Replace different representations of apostrophes with a single consistent representation\n",
    "    text = text.replace(\"’\", \"'\")  # Replace curly apostrophe with straight apostrophe\n",
    "\n",
    "    return text\n",
    "\n",
    "# Define function to preprocess text\n",
    "def preprocess_text(text):\n",
    "\n",
    "    # Lowercasing apostrophe\n",
    "    text = to_lowercase(text)\n",
    "\n",
    "    #Normalising\n",
    "    text = normalize_apostrophes(text)\n",
    "\n",
    "    # Removing Contractions\n",
    "\n",
    "    text = remove_contraction(text)\n",
    "\n",
    "    # Converting number to words\n",
    "    text = convert_numbers_to_words(text)\n",
    "\n",
    "    # Removing URLs\n",
    "    text = remove_urls(text)\n",
    "\n",
    "    # Removing special characters\n",
    "    text = remove_special_characters(text)\n",
    "\n",
    "    # Tokenization and removing stopwords\n",
    "    tokens = text.split()\n",
    "    tokens = [token for token in tokens if token not in english_stopwords]\n",
    "\n",
    "    # Joining tokens\n",
    "    text = ' '.join(tokens)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_contraction(text):\n",
    "   # Define contractions\n",
    "    contractions = {\n",
    "        \"ain't\": \"am not / is not / are not / has not / have not\",\n",
    "        \"aren't\": \"are not\",\n",
    "        \"can't\": \"cannot\",\n",
    "        \"can't've\": \"cannot have\",\n",
    "        \"'cause\": \"because\",\n",
    "        \"could've\": \"could have\",\n",
    "        \"couldn't\": \"could not\",\n",
    "        \"couldn't've\": \"could not have\",\n",
    "        \"didn't\": \"did not\",\n",
    "        \"doesn't\": \"does not\",\n",
    "        \"don't\": \"do not\",\n",
    "        \"hadn't\": \"had not\",\n",
    "        \"hadn't've\": \"had not have\",\n",
    "        \"hasn't\": \"has not\",\n",
    "        \"haven't\": \"have not\",\n",
    "        \"he'd\": \"he would / he had\",\n",
    "        \"he'd've\": \"he would have\",\n",
    "        \"he'll\": \"he will\",\n",
    "        \"he'll've\": \"he will have\",\n",
    "        \"he's\": \"he is / he has\",\n",
    "        \"how'd\": \"how did\",\n",
    "        \"how'd'y\": \"how do you\",\n",
    "        \"how'll\": \"how will\",\n",
    "        \"how's\": \"how is / how has / how does\",\n",
    "        \"i'd\": \"i would / I had\",\n",
    "        \"i'd've\": \"i would have\",\n",
    "        \"i'll\": \"i will\",\n",
    "        \"i'll've\": \"i will have\",\n",
    "        \"i'm\": \"i am\",\n",
    "        \"i've\": \"i have\",\n",
    "        \"isn't\": \"is not\",\n",
    "        \"it'd\": \"it would / it had\",\n",
    "        \"it'd've\": \"it would have\",\n",
    "        \"it'll\": \"it will\",\n",
    "        \"it'll've\": \"it will have\",\n",
    "        \"it's\": \"it is / it has\",\n",
    "        \"let's\": \"let us\",\n",
    "        \"ma'am\": \"madam\",\n",
    "        \"mayn't\": \"may not\",\n",
    "        \"might've\": \"might have\",\n",
    "        \"mightn't\": \"might not\",\n",
    "        \"mightn't've\": \"might not have\",\n",
    "        \"must've\": \"must have\",\n",
    "        \"mustn't\": \"must not\",\n",
    "        \"mustn't've\": \"must not have\",\n",
    "        \"needn't\": \"need not\",\n",
    "        \"needn't've\": \"need not have\",\n",
    "        \"o'clock\": \"of the clock\",\n",
    "        \"oughtn't\": \"ought not\",\n",
    "        \"oughtn't've\": \"ought not have\",\n",
    "        \"shan't\": \"shall not\",\n",
    "        \"sha'n't\": \"shall not\",\n",
    "        \"shan't've\": \"shall not have\",\n",
    "        \"she'd\": \"she would / she had\",\n",
    "        \"she'd've\": \"she would have\",\n",
    "        \"she'll\": \"she will\",\n",
    "        \"she'll've\": \"she will have\",\n",
    "        \"she's\": \"she is / she has\",\n",
    "        \"should've\": \"should have\",\n",
    "        \"shouldn't\": \"should not\",\n",
    "        \"shouldn't've\": \"should not have\",\n",
    "        \"so've\": \"so have\",\n",
    "        \"so's\": \"so is / so has\",\n",
    "        \"that'd\": \"that would / that had\",\n",
    "        \"that'd've\": \"that would have\",\n",
    "        \"that's\": \"that is / that has\",\n",
    "        \"there'd\": \"there would / there had\",\n",
    "        \"there'd've\": \"there would have\",\n",
    "        \"there's\": \"there is / there has\",\n",
    "        \"they'd\": \"they would / they had\",\n",
    "        \"they'd've\": \"they would have\",\n",
    "        \"they'll\": \"they will\",\n",
    "        \"they'll've\": \"they will have\",\n",
    "        \"they're\": \"they are\",\n",
    "        \"they've\": \"they have\",\n",
    "        \"to've\": \"to have\",\n",
    "        \"wasn't\": \"was not\",\n",
    "        \"we'd\": \"we would / we had\",\n",
    "        \"we'd've\": \"we would have\",\n",
    "        \"we'll\": \"we will\",\n",
    "        \"we'll've\": \"we will have\",\n",
    "        \"we're\": \"we are\",\n",
    "        \"we've\": \"we have\",\n",
    "        \"weren't\": \"were not\",\n",
    "        \"what'll\": \"what will\",\n",
    "        \"what'll've\": \"what will have\",\n",
    "        \"what're\": \"what are\",\n",
    "        \"what's\": \"what is / what has\",\n",
    "        \"what've\": \"what have\",\n",
    "        \"when's\": \"when is / when has\",\n",
    "        \"when've\": \"when have\",\n",
    "        \"where'd\": \"where did\",\n",
    "        \"where's\": \"where is / where has\",\n",
    "        \"where've\": \"where have\",\n",
    "        \"who'll\": \"who will\",\n",
    "        \"who'll've\": \"who will have\",\n",
    "        \"who's\": \"who is / who has\",\n",
    "        \"who've\": \"who have\",\n",
    "        \"why's\": \"why is / why has\",\n",
    "        \"why've\": \"why have\",\n",
    "        \"will've\": \"will have\",\n",
    "        \"won't\": \"will not\",\n",
    "        \"won't've\": \"will not have\",\n",
    "        \"would've\": \"would have\",\n",
    "        \"wouldn't\": \"would not\",\n",
    "        \"wouldn't've\": \"would not have\",\n",
    "        \"y'all\": \"you all\",\n",
    "        \"y'all'd\": \"you all would\",\n",
    "        \"y'all'd've\": \"you all would have\",\n",
    "        \"y'all're\": \"you all are\",\n",
    "        \"y'all've\": \"you all have\",\n",
    "        \"you'd\": \"you would / you had\",\n",
    "        \"you'd've\": \"you would have\",\n",
    "        \"you'll\": \"you will\",\n",
    "        \"you'll've\": \"you will have\",\n",
    "        \"you're\": \"you are\",\n",
    "        \"you've\": \"you have\"\n",
    "    }\n",
    "     # Expanding contractions\n",
    "    for contraction, expansion in contractions.items():\n",
    "        text = text.replace(contraction, expansion)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Function to remove convert number to words\n",
    "def convert_numbers_to_words(text):\n",
    "    # Define a dictionary mapping numeric words to their corresponding words\n",
    "    num_words = {\n",
    "        '0': 'zero',\n",
    "        '1': 'one',\n",
    "        '2': 'two',\n",
    "        '3': 'three',\n",
    "        '4': 'four',\n",
    "        '5': 'five',\n",
    "        '6': 'six',\n",
    "        '7': 'seven',\n",
    "        '8': 'eight',\n",
    "        '9': 'nine'\n",
    "    }\n",
    "     # Converting numbers to words\n",
    "    for digit, word in num_words.items():\n",
    "        text = text.replace(digit, word)\n",
    "    return text\n",
    "\n",
    "def to_lowercase(text):\n",
    "    lowercase_text = ''\n",
    "    for char in text:\n",
    "        # Check if character is uppercase\n",
    "        if 'A' <= char <= 'Z':\n",
    "            # Convert uppercase to lowercase\n",
    "            lowercase_text += chr(ord(char) + 32)\n",
    "        else:\n",
    "            lowercase_text += char\n",
    "    return lowercase_text\n",
    "\n",
    "\n",
    "# Function to remove special characters\n",
    "def remove_special_characters(text):\n",
    "    # Define special characters\n",
    "    special_chars = {'!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=',\n",
    "                     '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~'}\n",
    "    return ''.join(char for char in text if char not in special_chars)\n",
    "\n",
    "# Function to remove URLs\n",
    "def remove_urls(text):\n",
    "    # Split text into words\n",
    "    words = text.split()\n",
    "    # Filter out words that do not start with 'http' or 'https'\n",
    "    filtered_words = [word for word in words if not (word.startswith('http://') or word.startswith('https://'))]\n",
    "    # Join the filtered words back into a string\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "#import demoji\n",
    "#demoji.download_codes()\n",
    "def emo(text):\n",
    "    temp=emoji.demojize(text,delimiters=(\" \",\" \"))\n",
    "    temp=temp.replace(\"_\",\"  \")\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['emo']=data[\"text\"].apply(lambda x:emo(x))\n",
    "data[\"clean_text\"]=data['emo'].apply(lambda X: preprocess_text(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>emo</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1382343793341575169</td>\n",
       "      <td>@IrvineWelsh I don’t know about you Irvine but...</td>\n",
       "      <td>0</td>\n",
       "      <td>@IrvineWelsh I don’t know about you Irvine but...</td>\n",
       "      <td>irvinewelsh know irvine keep told covid exist ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1377631738692796417</td>\n",
       "      <td>I bet money if i went n took a covid test righ...</td>\n",
       "      <td>0</td>\n",
       "      <td>I bet money if i went n took a covid test righ...</td>\n",
       "      <td>bet money went n took covid test right imma te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1386448010029240326</td>\n",
       "      <td>@JamesMelville My wife received a POSITIVE Cov...</td>\n",
       "      <td>0</td>\n",
       "      <td>@JamesMelville My wife received a POSITIVE Cov...</td>\n",
       "      <td>jamesmelville wife received positive covid tes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1361342676340211717</td>\n",
       "      <td>Out of the 180,000+ people who have had the tw...</td>\n",
       "      <td>0</td>\n",
       "      <td>Out of the 180,000+ people who have had the tw...</td>\n",
       "      <td>oneeightzerozerozerozero people two vaccine sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1386757983254765569</td>\n",
       "      <td>My whole family is sick af and here I am now i...</td>\n",
       "      <td>0</td>\n",
       "      <td>My whole family is sick af and here I am now i...</td>\n",
       "      <td>whole family sick af hospital heart palpitatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1382001700853125122</td>\n",
       "      <td>@renfrew1962 @PeakePolly @J_Deliciouso I'm not...</td>\n",
       "      <td>0</td>\n",
       "      <td>@renfrew1962 @PeakePolly @J  Deliciouso I'm no...</td>\n",
       "      <td>renfrewoneninesixtwo peakepolly j deliciouso d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1383272654212272136</td>\n",
       "      <td>Test came back positive, no surprise. I have c...</td>\n",
       "      <td>1</td>\n",
       "      <td>Test came back positive, no surprise. I have c...</td>\n",
       "      <td>test came back positive surprise covid fully v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1374479299047084035</td>\n",
       "      <td>My Pawpaw has been in the hospital a few days....</td>\n",
       "      <td>0</td>\n",
       "      <td>My Pawpaw has been in the hospital a few days....</td>\n",
       "      <td>pawpaw hospital days got special approval come...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1354020426620547072</td>\n",
       "      <td>@MattHancock 4 people I know had covid and rec...</td>\n",
       "      <td>0</td>\n",
       "      <td>@MattHancock 4 people I know had covid and rec...</td>\n",
       "      <td>matthancock four people know covid recovered e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1362671045136809985</td>\n",
       "      <td>I’m going to sound like I have lost my marbles...</td>\n",
       "      <td>1</td>\n",
       "      <td>I’m going to sound like I have lost my marbles...</td>\n",
       "      <td>going sound like lost marbles felt well since ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1373077971658022918</td>\n",
       "      <td>I just tested positive for Covid-19 from two s...</td>\n",
       "      <td>1</td>\n",
       "      <td>I just tested positive for Covid-19 from two s...</td>\n",
       "      <td>tested positive covidonenine two separate clin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1373076070312730633</td>\n",
       "      <td>Someone I love very much was diagnosed with co...</td>\n",
       "      <td>0</td>\n",
       "      <td>Someone I love very much was diagnosed with co...</td>\n",
       "      <td>someone love much diagnosed covid onenine toda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1331292744489250816</td>\n",
       "      <td>Dear @PeterHotez ,Serious question about Vacci...</td>\n",
       "      <td>0</td>\n",
       "      <td>Dear @PeterHotez ,Serious question about Vacci...</td>\n",
       "      <td>dear peterhotez serious question vaccinein one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1379116535726415874</td>\n",
       "      <td>As I was in the ER last night I overheard a co...</td>\n",
       "      <td>1</td>\n",
       "      <td>As I was in the ER last night I overheard a co...</td>\n",
       "      <td>er last night overheard conversation someone w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1357823724192296960</td>\n",
       "      <td>@jrlsilverman @dilleradollar @OregonGovBrown 💡...</td>\n",
       "      <td>0</td>\n",
       "      <td>@jrlsilverman @dilleradollar @OregonGovBrown  ...</td>\n",
       "      <td>jrlsilverman dilleradollar oregongovbrown ligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1376702269991890945</td>\n",
       "      <td>Today: 1 person (after overnight code) in ICU ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Today: 1 person (after overnight code) in ICU ...</td>\n",
       "      <td>today one person overnight code icu wcovid fiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1377607714524831745</td>\n",
       "      <td>@Asilverlining20 @TVpsychologist @NHSuk It’s b...</td>\n",
       "      <td>0</td>\n",
       "      <td>@Asilverlining20 @TVpsychologist @NHSuk It’s b...</td>\n",
       "      <td>asilverliningtwozero tvpsychologist nhsuk year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1388377556097904640</td>\n",
       "      <td>These side effects are CRAZY!!! Got the second...</td>\n",
       "      <td>0</td>\n",
       "      <td>These side effects are CRAZY!!! Got the second...</td>\n",
       "      <td>side effects crazy got second pfizer vaccine t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1377509820425723912</td>\n",
       "      <td>@BethMooreLPM Continuing to #Pray for Healing ...</td>\n",
       "      <td>0</td>\n",
       "      <td>@BethMooreLPM Continuing to #Pray for Healing ...</td>\n",
       "      <td>bethmoorelpm continuing pray healing miracles ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1383382420234280964</td>\n",
       "      <td>@mstranack @GillianMcKeith Just spoke to Hayde...</td>\n",
       "      <td>0</td>\n",
       "      <td>@mstranack @GillianMcKeith Just spoke to Hayde...</td>\n",
       "      <td>mstranack gillianmckeith spoke hayden morning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1333413081083310081</td>\n",
       "      <td>There are Lies, Damn lies, and Statistics.http...</td>\n",
       "      <td>0</td>\n",
       "      <td>There are Lies, Damn lies, and Statistics.http...</td>\n",
       "      <td>lies damn lies statisticshttpstcozerovaethreey...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1386707720317935617</td>\n",
       "      <td>@basakcoruhUW @nickmmark I think what hurts th...</td>\n",
       "      <td>0</td>\n",
       "      <td>@basakcoruhUW @nickmmark I think what hurts th...</td>\n",
       "      <td>basakcoruhuw nickmmark think hurts physicians ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1375292877195120640</td>\n",
       "      <td>@Tempid_ I actually tested positive for covid....</td>\n",
       "      <td>1</td>\n",
       "      <td>@Tempid   I actually tested positive for covid...</td>\n",
       "      <td>tempid actually tested positive covid sick two...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1350649856830828546</td>\n",
       "      <td>@IA___09 @leighjoyus @lc5190 @FlatEarthCity It...</td>\n",
       "      <td>0</td>\n",
       "      <td>@IA      09 @leighjoyus @lc5190 @FlatEarthCity...</td>\n",
       "      <td>ia zeronine leighjoyus lcfiveoneninezero flate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1377254105752690696</td>\n",
       "      <td>A year ago, on this date, I made the decision ...</td>\n",
       "      <td>0</td>\n",
       "      <td>A year ago, on this date, I made the decision ...</td>\n",
       "      <td>year ago date made decision bring husband twoz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1383590378712956929</td>\n",
       "      <td>One week back from Daytona, my whole family ge...</td>\n",
       "      <td>1</td>\n",
       "      <td>One week back from Daytona, my whole family ge...</td>\n",
       "      <td>one week back daytona whole family gets really...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1388238564220030977</td>\n",
       "      <td>@TheDamaniFelder I still don’t know anyone who...</td>\n",
       "      <td>0</td>\n",
       "      <td>@TheDamaniFelder I still don’t know anyone who...</td>\n",
       "      <td>thedamanifelder still know anyone died covid k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1373218284129157120</td>\n",
       "      <td>@PointCrow Honestly just a text back from her ...</td>\n",
       "      <td>0</td>\n",
       "      <td>@PointCrow Honestly just a text back from her ...</td>\n",
       "      <td>pointcrow honestly text back telling “goodbye ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1385316180739624972</td>\n",
       "      <td>I have Covid. Yaay... 🙄🙄 Went to get tested, b...</td>\n",
       "      <td>0</td>\n",
       "      <td>I have Covid. Yaay...  face  with  rolling  ey...</td>\n",
       "      <td>covid yaay face rolling eyes face rolling eyes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1386017989053624320</td>\n",
       "      <td>@AntiLockdownAl2 @Rainbowandsteel Totally ...s...</td>\n",
       "      <td>0</td>\n",
       "      <td>@AntiLockdownAl2 @Rainbowandsteel Totally ...s...</td>\n",
       "      <td>antilockdownaltwo rainbowandsteel totally some...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweet_id                                               text  \\\n",
       "0   1382343793341575169  @IrvineWelsh I don’t know about you Irvine but...   \n",
       "1   1377631738692796417  I bet money if i went n took a covid test righ...   \n",
       "2   1386448010029240326  @JamesMelville My wife received a POSITIVE Cov...   \n",
       "3   1361342676340211717  Out of the 180,000+ people who have had the tw...   \n",
       "4   1386757983254765569  My whole family is sick af and here I am now i...   \n",
       "5   1382001700853125122  @renfrew1962 @PeakePolly @J_Deliciouso I'm not...   \n",
       "6   1383272654212272136  Test came back positive, no surprise. I have c...   \n",
       "7   1374479299047084035  My Pawpaw has been in the hospital a few days....   \n",
       "8   1354020426620547072  @MattHancock 4 people I know had covid and rec...   \n",
       "9   1362671045136809985  I’m going to sound like I have lost my marbles...   \n",
       "10  1373077971658022918  I just tested positive for Covid-19 from two s...   \n",
       "11  1373076070312730633  Someone I love very much was diagnosed with co...   \n",
       "12  1331292744489250816  Dear @PeterHotez ,Serious question about Vacci...   \n",
       "13  1379116535726415874  As I was in the ER last night I overheard a co...   \n",
       "14  1357823724192296960  @jrlsilverman @dilleradollar @OregonGovBrown 💡...   \n",
       "15  1376702269991890945  Today: 1 person (after overnight code) in ICU ...   \n",
       "16  1377607714524831745  @Asilverlining20 @TVpsychologist @NHSuk It’s b...   \n",
       "17  1388377556097904640  These side effects are CRAZY!!! Got the second...   \n",
       "18  1377509820425723912  @BethMooreLPM Continuing to #Pray for Healing ...   \n",
       "19  1383382420234280964  @mstranack @GillianMcKeith Just spoke to Hayde...   \n",
       "20  1333413081083310081  There are Lies, Damn lies, and Statistics.http...   \n",
       "21  1386707720317935617  @basakcoruhUW @nickmmark I think what hurts th...   \n",
       "22  1375292877195120640  @Tempid_ I actually tested positive for covid....   \n",
       "23  1350649856830828546  @IA___09 @leighjoyus @lc5190 @FlatEarthCity It...   \n",
       "24  1377254105752690696  A year ago, on this date, I made the decision ...   \n",
       "25  1383590378712956929  One week back from Daytona, my whole family ge...   \n",
       "26  1388238564220030977  @TheDamaniFelder I still don’t know anyone who...   \n",
       "27  1373218284129157120  @PointCrow Honestly just a text back from her ...   \n",
       "28  1385316180739624972  I have Covid. Yaay... 🙄🙄 Went to get tested, b...   \n",
       "29  1386017989053624320  @AntiLockdownAl2 @Rainbowandsteel Totally ...s...   \n",
       "\n",
       "    label                                                emo  \\\n",
       "0       0  @IrvineWelsh I don’t know about you Irvine but...   \n",
       "1       0  I bet money if i went n took a covid test righ...   \n",
       "2       0  @JamesMelville My wife received a POSITIVE Cov...   \n",
       "3       0  Out of the 180,000+ people who have had the tw...   \n",
       "4       0  My whole family is sick af and here I am now i...   \n",
       "5       0  @renfrew1962 @PeakePolly @J  Deliciouso I'm no...   \n",
       "6       1  Test came back positive, no surprise. I have c...   \n",
       "7       0  My Pawpaw has been in the hospital a few days....   \n",
       "8       0  @MattHancock 4 people I know had covid and rec...   \n",
       "9       1  I’m going to sound like I have lost my marbles...   \n",
       "10      1  I just tested positive for Covid-19 from two s...   \n",
       "11      0  Someone I love very much was diagnosed with co...   \n",
       "12      0  Dear @PeterHotez ,Serious question about Vacci...   \n",
       "13      1  As I was in the ER last night I overheard a co...   \n",
       "14      0  @jrlsilverman @dilleradollar @OregonGovBrown  ...   \n",
       "15      0  Today: 1 person (after overnight code) in ICU ...   \n",
       "16      0  @Asilverlining20 @TVpsychologist @NHSuk It’s b...   \n",
       "17      0  These side effects are CRAZY!!! Got the second...   \n",
       "18      0  @BethMooreLPM Continuing to #Pray for Healing ...   \n",
       "19      0  @mstranack @GillianMcKeith Just spoke to Hayde...   \n",
       "20      0  There are Lies, Damn lies, and Statistics.http...   \n",
       "21      0  @basakcoruhUW @nickmmark I think what hurts th...   \n",
       "22      1  @Tempid   I actually tested positive for covid...   \n",
       "23      0  @IA      09 @leighjoyus @lc5190 @FlatEarthCity...   \n",
       "24      0  A year ago, on this date, I made the decision ...   \n",
       "25      1  One week back from Daytona, my whole family ge...   \n",
       "26      0  @TheDamaniFelder I still don’t know anyone who...   \n",
       "27      0  @PointCrow Honestly just a text back from her ...   \n",
       "28      0  I have Covid. Yaay...  face  with  rolling  ey...   \n",
       "29      0  @AntiLockdownAl2 @Rainbowandsteel Totally ...s...   \n",
       "\n",
       "                                           clean_text  \n",
       "0   irvinewelsh know irvine keep told covid exist ...  \n",
       "1   bet money went n took covid test right imma te...  \n",
       "2   jamesmelville wife received positive covid tes...  \n",
       "3   oneeightzerozerozerozero people two vaccine sh...  \n",
       "4   whole family sick af hospital heart palpitatio...  \n",
       "5   renfrewoneninesixtwo peakepolly j deliciouso d...  \n",
       "6   test came back positive surprise covid fully v...  \n",
       "7   pawpaw hospital days got special approval come...  \n",
       "8   matthancock four people know covid recovered e...  \n",
       "9   going sound like lost marbles felt well since ...  \n",
       "10  tested positive covidonenine two separate clin...  \n",
       "11  someone love much diagnosed covid onenine toda...  \n",
       "12  dear peterhotez serious question vaccinein one...  \n",
       "13  er last night overheard conversation someone w...  \n",
       "14  jrlsilverman dilleradollar oregongovbrown ligh...  \n",
       "15  today one person overnight code icu wcovid fiv...  \n",
       "16  asilverliningtwozero tvpsychologist nhsuk year...  \n",
       "17  side effects crazy got second pfizer vaccine t...  \n",
       "18  bethmoorelpm continuing pray healing miracles ...  \n",
       "19  mstranack gillianmckeith spoke hayden morning ...  \n",
       "20  lies damn lies statisticshttpstcozerovaethreey...  \n",
       "21  basakcoruhuw nickmmark think hurts physicians ...  \n",
       "22  tempid actually tested positive covid sick two...  \n",
       "23  ia zeronine leighjoyus lcfiveoneninezero flate...  \n",
       "24  year ago date made decision bring husband twoz...  \n",
       "25  one week back daytona whole family gets really...  \n",
       "26  thedamanifelder still know anyone died covid k...  \n",
       "27  pointcrow honestly text back telling “goodbye ...  \n",
       "28  covid yaay face rolling eyes face rolling eyes...  \n",
       "29  antilockdownaltwo rainbowandsteel totally some...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program to read and display various kinds of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to read and display .png file\n",
    "import cv2\n",
    "\n",
    "image=cv2.imread('flower.png')\n",
    "cv2.imshow(\"image\", image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to read and display .jpg file\n",
    "import cv2\n",
    "\n",
    "image=cv2.imread('dog.jpg')\n",
    "cv2.imshow(\"image\", image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to read and display .gif file\n",
    "\n",
    "import cv2\n",
    "\n",
    "def show_gif(file_path):\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        cv2.imshow('GIF Viewer', frame)\n",
    "        if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "show_gif(\"moon.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age Range</th>\n",
       "      <th>Head Size(cm^3)</th>\n",
       "      <th>Brain Weight(grams)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4512</td>\n",
       "      <td>1530.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3738</td>\n",
       "      <td>1297.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4261</td>\n",
       "      <td>1335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3777</td>\n",
       "      <td>1282.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4177</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3214</td>\n",
       "      <td>1110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3394</td>\n",
       "      <td>1215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3233</td>\n",
       "      <td>1104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3352</td>\n",
       "      <td>1170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3391</td>\n",
       "      <td>1120.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>237 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender  Age Range  Head Size(cm^3)  Brain Weight(grams)\n",
       "0       1.0        1.0             4512               1530.0\n",
       "1       NaN        1.0             3738               1297.0\n",
       "2       1.0        1.0             4261               1335.0\n",
       "3       1.0        1.0             3777               1282.0\n",
       "4       1.0        1.0             4177                  NaN\n",
       "..      ...        ...              ...                  ...\n",
       "232     2.0        2.0             3214               1110.0\n",
       "233     2.0        2.0             3394               1215.0\n",
       "234     2.0        2.0             3233               1104.0\n",
       "235     2.0        2.0             3352               1170.0\n",
       "236     2.0        2.0             3391               1120.0\n",
       "\n",
       "[237 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code to read and display .csv file\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "csvdata=pd.read_csv(\"headbrain.csv\")\n",
    "\n",
    "csvdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>50</th>\n",
       "      <th>5</th>\n",
       "      <th>881250949</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>5</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>880</td>\n",
       "      <td>476</td>\n",
       "      <td>3</td>\n",
       "      <td>880175444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>716</td>\n",
       "      <td>204</td>\n",
       "      <td>5</td>\n",
       "      <td>879795543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>276</td>\n",
       "      <td>1090</td>\n",
       "      <td>1</td>\n",
       "      <td>874795795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>13</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "      <td>882399156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100001</th>\n",
       "      <td>12</td>\n",
       "      <td>203</td>\n",
       "      <td>3</td>\n",
       "      <td>879959583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100002 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    50  5  881250949\n",
       "0         0   172  5  881250949\n",
       "1         0   133  1  881250949\n",
       "2       196   242  3  881250949\n",
       "3       186   302  3  891717742\n",
       "4        22   377  1  878887116\n",
       "...     ...   ... ..        ...\n",
       "99997   880   476  3  880175444\n",
       "99998   716   204  5  879795543\n",
       "99999   276  1090  1  874795795\n",
       "100000   13   225  2  882399156\n",
       "100001   12   203  3  879959583\n",
       "\n",
       "[100002 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code to read and display .tsv file\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "tsvdata=pd.read_csv(\"file.tsv\", sep = \"\\t\")\n",
    "\n",
    "tsvdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number 1</th>\n",
       "      <th>Number 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.5277</td>\n",
       "      <td>9.13020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.5186</td>\n",
       "      <td>13.66200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0032</td>\n",
       "      <td>11.85400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.8598</td>\n",
       "      <td>6.82330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.3829</td>\n",
       "      <td>11.88600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>5.8707</td>\n",
       "      <td>7.20290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5.3054</td>\n",
       "      <td>1.98690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>8.2934</td>\n",
       "      <td>0.14454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>13.3940</td>\n",
       "      <td>9.05510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5.4369</td>\n",
       "      <td>0.61705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number 1  Number 2\n",
       "0     5.5277   9.13020\n",
       "1     8.5186  13.66200\n",
       "2     7.0032  11.85400\n",
       "3     5.8598   6.82330\n",
       "4     8.3829  11.88600\n",
       "..       ...       ...\n",
       "91    5.8707   7.20290\n",
       "92    5.3054   1.98690\n",
       "93    8.2934   0.14454\n",
       "94   13.3940   9.05510\n",
       "95    5.4369   0.61705\n",
       "\n",
       "[96 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code to read and display excel file\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "exceldata=pd.read_excel(\"exceldata.xlsx\", names = [\"Number 1\" , \"Number 2\"])\n",
    "\n",
    "exceldata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Branch</th>\n",
       "      <th>Year</th>\n",
       "      <th>CGPA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nikhil</td>\n",
       "      <td>CS</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sanchit</td>\n",
       "      <td>CS</td>\n",
       "      <td>2</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aditya</td>\n",
       "      <td>IT</td>\n",
       "      <td>2</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sagar</td>\n",
       "      <td>ECE</td>\n",
       "      <td>1</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prateek</td>\n",
       "      <td>ME</td>\n",
       "      <td>3</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sahil</td>\n",
       "      <td>EEE</td>\n",
       "      <td>2</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name Branch  Year  CGPA\n",
       "0   Nikhil     CS     2   9.0\n",
       "1  Sanchit     CS     2   9.1\n",
       "2   Aditya     IT     2   9.3\n",
       "3    Sagar    ECE     1   9.5\n",
       "4  Prateek     ME     3   7.8\n",
       "5    Sahil    EEE     2   9.1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code to read and display .txt file\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "txtdata= pd.read_csv(\"records.txt\", sep=\" \")\n",
    "\n",
    "txtdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fruit': 'Apple', 'size': 'Large', 'color': 'Red'}\n"
     ]
    }
   ],
   "source": [
    "#code to read and display json file\n",
    "\n",
    "import json\n",
    "with open(\"sample1-json.json\", 'r') as f:\n",
    "    json_ob = json.load(f)\n",
    "print(json_ob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Segment</th>\n",
       "      <th>Country</th>\n",
       "      <th>Product</th>\n",
       "      <th>Discount Band</th>\n",
       "      <th>Units Sold</th>\n",
       "      <th>Manufacturing Price</th>\n",
       "      <th>Sale Price</th>\n",
       "      <th>Gross Sales</th>\n",
       "      <th>Discounts</th>\n",
       "      <th>Sales</th>\n",
       "      <th>COGS</th>\n",
       "      <th>Profit</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month Number</th>\n",
       "      <th>Month Name</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Government</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Carretera</td>\n",
       "      <td>None</td>\n",
       "      <td>1618.5</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>32370.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>32370.00</td>\n",
       "      <td>16185.0</td>\n",
       "      <td>16185.00</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Government</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Carretera</td>\n",
       "      <td>None</td>\n",
       "      <td>1321.0</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>26420.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26420.00</td>\n",
       "      <td>13210.0</td>\n",
       "      <td>13210.00</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Midmarket</td>\n",
       "      <td>France</td>\n",
       "      <td>Carretera</td>\n",
       "      <td>None</td>\n",
       "      <td>2178.0</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>32670.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>32670.00</td>\n",
       "      <td>21780.0</td>\n",
       "      <td>10890.00</td>\n",
       "      <td>2014-06-01</td>\n",
       "      <td>6</td>\n",
       "      <td>June</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Midmarket</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Carretera</td>\n",
       "      <td>None</td>\n",
       "      <td>888.0</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>13320.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13320.00</td>\n",
       "      <td>8880.0</td>\n",
       "      <td>4440.00</td>\n",
       "      <td>2014-06-01</td>\n",
       "      <td>6</td>\n",
       "      <td>June</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Midmarket</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>Carretera</td>\n",
       "      <td>None</td>\n",
       "      <td>2470.0</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>37050.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37050.00</td>\n",
       "      <td>24700.0</td>\n",
       "      <td>12350.00</td>\n",
       "      <td>2014-06-01</td>\n",
       "      <td>6</td>\n",
       "      <td>June</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>Small Business</td>\n",
       "      <td>France</td>\n",
       "      <td>Amarilla</td>\n",
       "      <td>High</td>\n",
       "      <td>2475.0</td>\n",
       "      <td>260</td>\n",
       "      <td>300</td>\n",
       "      <td>742500.0</td>\n",
       "      <td>111375.00</td>\n",
       "      <td>631125.00</td>\n",
       "      <td>618750.0</td>\n",
       "      <td>12375.00</td>\n",
       "      <td>2014-03-01</td>\n",
       "      <td>3</td>\n",
       "      <td>March</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>Small Business</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>Amarilla</td>\n",
       "      <td>High</td>\n",
       "      <td>546.0</td>\n",
       "      <td>260</td>\n",
       "      <td>300</td>\n",
       "      <td>163800.0</td>\n",
       "      <td>24570.00</td>\n",
       "      <td>139230.00</td>\n",
       "      <td>136500.0</td>\n",
       "      <td>2730.00</td>\n",
       "      <td>2014-10-01</td>\n",
       "      <td>10</td>\n",
       "      <td>October</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>Government</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>Montana</td>\n",
       "      <td>High</td>\n",
       "      <td>1368.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>9576.0</td>\n",
       "      <td>1436.40</td>\n",
       "      <td>8139.60</td>\n",
       "      <td>6840.0</td>\n",
       "      <td>1299.60</td>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>2</td>\n",
       "      <td>February</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>Government</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Paseo</td>\n",
       "      <td>High</td>\n",
       "      <td>723.0</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>5061.0</td>\n",
       "      <td>759.15</td>\n",
       "      <td>4301.85</td>\n",
       "      <td>3615.0</td>\n",
       "      <td>686.85</td>\n",
       "      <td>2014-04-01</td>\n",
       "      <td>4</td>\n",
       "      <td>April</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>Channel Partners</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>VTT</td>\n",
       "      <td>High</td>\n",
       "      <td>1806.0</td>\n",
       "      <td>250</td>\n",
       "      <td>12</td>\n",
       "      <td>21672.0</td>\n",
       "      <td>3250.80</td>\n",
       "      <td>18421.20</td>\n",
       "      <td>5418.0</td>\n",
       "      <td>13003.20</td>\n",
       "      <td>2014-05-01</td>\n",
       "      <td>5</td>\n",
       "      <td>May</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Segment                   Country    Product Discount Band  \\\n",
       "0          Government                    Canada  Carretera          None   \n",
       "1          Government                   Germany  Carretera          None   \n",
       "2           Midmarket                    France  Carretera          None   \n",
       "3           Midmarket                   Germany  Carretera          None   \n",
       "4           Midmarket                    Mexico  Carretera          None   \n",
       "..                ...                       ...        ...           ...   \n",
       "695    Small Business                    France   Amarilla          High   \n",
       "696    Small Business                    Mexico   Amarilla          High   \n",
       "697        Government                    Mexico    Montana          High   \n",
       "698        Government                    Canada      Paseo          High   \n",
       "699  Channel Partners  United States of America        VTT          High   \n",
       "\n",
       "     Units Sold  Manufacturing Price  Sale Price  Gross Sales  Discounts  \\\n",
       "0        1618.5                    3          20      32370.0       0.00   \n",
       "1        1321.0                    3          20      26420.0       0.00   \n",
       "2        2178.0                    3          15      32670.0       0.00   \n",
       "3         888.0                    3          15      13320.0       0.00   \n",
       "4        2470.0                    3          15      37050.0       0.00   \n",
       "..          ...                  ...         ...          ...        ...   \n",
       "695      2475.0                  260         300     742500.0  111375.00   \n",
       "696       546.0                  260         300     163800.0   24570.00   \n",
       "697      1368.0                    5           7       9576.0    1436.40   \n",
       "698       723.0                   10           7       5061.0     759.15   \n",
       "699      1806.0                  250          12      21672.0    3250.80   \n",
       "\n",
       "         Sales      COGS    Profit       Date  Month Number Month Name  Year  \n",
       "0     32370.00   16185.0  16185.00 2014-01-01             1    January  2014  \n",
       "1     26420.00   13210.0  13210.00 2014-01-01             1    January  2014  \n",
       "2     32670.00   21780.0  10890.00 2014-06-01             6       June  2014  \n",
       "3     13320.00    8880.0   4440.00 2014-06-01             6       June  2014  \n",
       "4     37050.00   24700.0  12350.00 2014-06-01             6       June  2014  \n",
       "..         ...       ...       ...        ...           ...        ...   ...  \n",
       "695  631125.00  618750.0  12375.00 2014-03-01             3      March  2014  \n",
       "696  139230.00  136500.0   2730.00 2014-10-01            10    October  2014  \n",
       "697    8139.60    6840.0   1299.60 2014-02-01             2   February  2014  \n",
       "698    4301.85    3615.0    686.85 2014-04-01             4      April  2014  \n",
       "699   18421.20    5418.0  13003.20 2014-05-01             5        May  2014  \n",
       "\n",
       "[700 rows x 16 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code to read and display excel file\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "exceldata=pd.read_excel(\"FinancialSample.xlsx\")\n",
    "\n",
    "exceldata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa\n",
      "  Downloading librosa-0.10.2.post1-py3-none-any.whl (260 kB)\n",
      "Collecting numba>=0.51.0\n",
      "  Downloading numba-0.58.1-cp38-cp38-win_amd64.whl (2.6 MB)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (1.5.0)\n",
      "Collecting pooch>=1.1\n",
      "  Downloading pooch-1.8.1-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (0.16.0)\n",
      "Collecting soundfile>=0.12.1\n",
      "  Downloading soundfile-0.12.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\yashushetty\\appdata\\roaming\\python\\python38\\site-packages (from librosa) (4.11.0)\n",
      "Collecting lazy-loader>=0.1\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (0.23.1)\n",
      "Collecting soxr>=0.3.2\n",
      "  Downloading soxr-0.3.7-cp38-cp38-win_amd64.whl (184 kB)\n",
      "Collecting numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3\n",
      "  Downloading numpy-1.24.4-cp38-cp38-win_amd64.whl (14.9 MB)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (1.0.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (4.4.2)\n",
      "Collecting audioread>=2.1.9\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.9\" in c:\\programdata\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (1.7.0)\n",
      "Collecting llvmlite<0.42,>=0.41.0dev0\n",
      "  Downloading llvmlite-0.41.1-cp38-cp38-win_amd64.whl (28.1 MB)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (2.24.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (20.4)\n",
      "Collecting platformdirs>=2.5.0\n",
      "  Downloading platformdirs-4.2.2-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.14.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (2.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.9\"->numba>=0.51.0->librosa) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.10)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->pooch>=1.1->librosa) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->pooch>=1.1->librosa) (1.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.20)\n",
      "Installing collected packages: numpy, llvmlite, numba, platformdirs, pooch, soundfile, lazy-loader, soxr, audioread, librosa\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.18.5\n",
      "    Uninstalling numpy-1.18.5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Access is denied: 'c:\\\\programdata\\\\anaconda3\\\\lib\\\\site-packages\\\\numpy\\\\compat\\\\py3k.py'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa\n",
      "  Using cached librosa-0.10.2.post1-py3-none-any.whl (260 kB)\n",
      "Collecting lazy-loader>=0.1\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Collecting numba>=0.51.0\n",
      "  Using cached numba-0.58.1-cp38-cp38-win_amd64.whl (2.6 MB)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (1.5.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (0.23.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\yashushetty\\appdata\\roaming\\python\\python38\\site-packages (from librosa) (4.11.0)\n",
      "Collecting numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3\n",
      "  Using cached numpy-1.24.4-cp38-cp38-win_amd64.whl (14.9 MB)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (0.16.0)\n",
      "Collecting pooch>=1.1\n",
      "  Using cached pooch-1.8.1-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (4.4.2)\n",
      "Collecting soxr>=0.3.2\n",
      "  Using cached soxr-0.3.7-cp38-cp38-win_amd64.whl (184 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\yashushetty\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: msgpack>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (1.0.0)\n",
      "Collecting soundfile>=0.12.1\n",
      "  Using cached soundfile-0.12.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "Collecting audioread>=2.1.9\n",
      "  Using cached audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from lazy-loader>=0.1->librosa) (20.4)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.9\" in c:\\programdata\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (1.7.0)\n",
      "Collecting llvmlite<0.42,>=0.41.0dev0\n",
      "  Using cached llvmlite-0.41.1-cp38-cp38-win_amd64.whl (28.1 MB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (2.1.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (2.24.0)\n",
      "Collecting platformdirs>=2.5.0\n",
      "  Using cached platformdirs-4.2.2-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.14.0)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->lazy-loader>=0.1->librosa) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->lazy-loader>=0.1->librosa) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.9\"->numba>=0.51.0->librosa) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.0.4)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.20)\n",
      "Installing collected packages: lazy-loader, llvmlite, numpy, numba, platformdirs, pooch, soxr, soundfile, audioread, librosa\n",
      "Successfully installed audioread-3.0.1 lazy-loader-0.4 librosa-0.10.2.post1 llvmlite-0.41.1 numba-0.58.1 numpy-1.24.4 platformdirs-4.2.2 pooch-1.8.1 soundfile-0.12.1 soxr-0.3.7\n"
     ]
    }
   ],
   "source": [
    "!pip install --user librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'int' from 'numpy' (C:\\Users\\yashushetty\\AppData\\Roaming\\Python\\Python38\\site-packages\\numpy\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a0692898cb38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Load audio file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0maudio_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"sample-3s.wav\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Play audio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\lazy_loader\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[0msubmod_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"{package_name}.{attr_to_modules[name]}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[0msubmod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubmod_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m             \u001b[0mattr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubmod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[1;31m# If the attribute lives in a file (module) with the same\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\lazy_loader\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mattr_to_modules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[0msubmod_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"{package_name}.{attr_to_modules[name]}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m             \u001b[0msubmod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubmod_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m             \u001b[0mattr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubmod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msoxr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlazy_loader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlazy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\signal\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m \"\"\"\n\u001b[1;32m--> 289\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msigtools\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mwaveforms\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_max_len_seq\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmax_len_seq\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\signal\\windows\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \"\"\"\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mwindows\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m __all__ = ['boxcar', 'triang', 'parzen', 'bohman', 'blackman', 'nuttall',\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\signal\\windows\\windows.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspecial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfft\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msp_fft\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m __all__ = ['boxcar', 'triang', 'parzen', 'bohman', 'blackman', 'nuttall',\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\special\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    634\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_ufuncs\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 636\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_basic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    637\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_basic\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\special\\_basic.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m                       poch, binom, hyp0f1)\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mspecfun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0morthogonal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_comb\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_comb_int\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\special\\orthogonal.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;31m# SciPy imports.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m from numpy import (exp, inf, pi, sqrt, floor, sin, cos, around, int,\n\u001b[0m\u001b[0;32m     80\u001b[0m                    hstack, arccos, arange)\n\u001b[0;32m     81\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'int' from 'numpy' (C:\\Users\\yashushetty\\AppData\\Roaming\\Python\\Python38\\site-packages\\numpy\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "from IPython.display import Audio\n",
    "\n",
    "# Load audio file\n",
    "audio_path = \"sample-3s.wav\"\n",
    "y, sr = librosa.load(audio_path)\n",
    "\n",
    "# Play audio\n",
    "Audio(data=y, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Path to the video file\n",
    "video_path = \"file_example.mp4\"\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if the video opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open the video.\")\n",
    "else:\n",
    "    # Create a flag to track window status\n",
    "    window_open = True\n",
    "    \n",
    "    # Loop through each frame in the video\n",
    "    while window_open:\n",
    "        # Read a frame from the video\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # If the frame was read successfully\n",
    "        if ret:\n",
    "            # Display the frame\n",
    "            cv2.imshow('Video', frame)\n",
    "\n",
    "            # Check for the 'q' key to quit\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            # Break the loop if the video has ended\n",
    "            break\n",
    "        \n",
    "        # Check if the window is still open\n",
    "        if cv2.getWindowProperty('Video', cv2.WND_PROP_VISIBLE) < 1:\n",
    "            window_open = False\n",
    "\n",
    "    # Release the video capture object and close the window\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
