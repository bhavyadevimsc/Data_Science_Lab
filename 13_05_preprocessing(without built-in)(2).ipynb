{"cells":[{"cell_type":"code","execution_count":null,"id":"6fd39d3b","metadata":{"id":"6fd39d3b"},"outputs":[],"source":["\n"]},{"cell_type":"code","execution_count":null,"id":"c07e5a7f","metadata":{"id":"c07e5a7f","outputId":"95f9e0f9-3ec9-4cc1-f02a-7cf92961e224"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet_id</th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1382343793341575169</td>\n","      <td>@IrvineWelsh I donâ€™t know about you Irvine but...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1377631738692796417</td>\n","      <td>I bet money if i went n took a covid test righ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1386448010029240326</td>\n","      <td>@JamesMelville My wife received a POSITIVE Cov...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1361342676340211717</td>\n","      <td>Out of the 180,000+ people who have had the tw...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1386757983254765569</td>\n","      <td>My whole family is sick af and here I am now i...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7595</th>\n","      <td>1370572921043701761</td>\n","      <td>@galaflux @efb_1 @DrJekyllHJ7 @DrLeanaWen Iâ€™m ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7596</th>\n","      <td>1381076072129695746</td>\n","      <td>@tabbattales @nursekelsey I ended up in the ho...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7597</th>\n","      <td>1378912704530935809</td>\n","      <td>@UNREALJUST @recDNA @CDCgov How do you know? M...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7598</th>\n","      <td>1366144349940183042</td>\n","      <td>@angela14387 no it cant be that!  I wonder wha...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7599</th>\n","      <td>1359849897068015620</td>\n","      <td>Berwick-based clinical care assistant Fiona Ma...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7600 rows Ã— 3 columns</p>\n","</div>"],"text/plain":["                 tweet_id                                               text  \\\n","0     1382343793341575169  @IrvineWelsh I donâ€™t know about you Irvine but...   \n","1     1377631738692796417  I bet money if i went n took a covid test righ...   \n","2     1386448010029240326  @JamesMelville My wife received a POSITIVE Cov...   \n","3     1361342676340211717  Out of the 180,000+ people who have had the tw...   \n","4     1386757983254765569  My whole family is sick af and here I am now i...   \n","...                   ...                                                ...   \n","7595  1370572921043701761  @galaflux @efb_1 @DrJekyllHJ7 @DrLeanaWen Iâ€™m ...   \n","7596  1381076072129695746  @tabbattales @nursekelsey I ended up in the ho...   \n","7597  1378912704530935809  @UNREALJUST @recDNA @CDCgov How do you know? M...   \n","7598  1366144349940183042  @angela14387 no it cant be that!  I wonder wha...   \n","7599  1359849897068015620  Berwick-based clinical care assistant Fiona Ma...   \n","\n","      label  \n","0         0  \n","1         0  \n","2         0  \n","3         0  \n","4         0  \n","...     ...  \n","7595      0  \n","7596      1  \n","7597      0  \n","7598      0  \n","7599      0  \n","\n","[7600 rows x 3 columns]"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","import pandas as pd\n","import os\n","dataset = pd.read_csv('training.tsv', sep='\\t')\n","dataset"]},{"cell_type":"code","execution_count":null,"id":"ba85462b","metadata":{"id":"ba85462b","outputId":"89eb25ff-88d6-4edf-fa2b-56ff8948f4b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['tweet_id', 'text', 'label'], dtype='object')\n"]}],"source":["print(dataset.columns)"]},{"cell_type":"code","execution_count":null,"id":"76071dc3","metadata":{"id":"76071dc3"},"outputs":[],"source":["data['label'].value.count"]},{"cell_type":"code","execution_count":null,"id":"ac9d9147","metadata":{"id":"ac9d9147"},"outputs":[],"source":["#  define your own list of stopwords\n","english_stopwords = set([\n","        \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\",\n","        \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\",\n","        \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\",\n","        \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\",\n","        \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\",\n","        \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\",\n","        \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\",\n","        \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\",\n","        \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\",\n","        \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\"\n","    ])\n","def preprocess(text):\n","     #lower case\n","    text=to_lower_case(text)\n","\n","    #remove contraction\n","    text = text.replace(\"â€™\", \"'\") #replace curly aposrophe with straight aposrophe\n","    text=remove_contraction(text)\n","\n","    # Replace digits with words\n","    text = replace_digits_with_words(text)\n","\n","     #remove url's\n","    text=remove_urls(text)\n","\n","    # Remove special characters (punctuation)\n","    text = remove_special_characters(text)\n","\n","    # Tokenize the text manually (splitting by whitespace)\n","    tokens = text.split()\n","    tokens = [token for token in tokens if token not in english_stopwords]\n","\n","    # Join tokens back into a string\n","    processed_text = \" \".join(tokens)\n","\n","    return processed_text\n","def remove_contraction(text):\n","    # Expand contractions manually (you can add more as needed)\n","    contractions_map = {\n","        \"isn't\": \"is not\",\n","        \"aren't\": \"are not\",\n","        \"wasn't\": \"was not\",\n","        \"weren't\": \"were not\",\n","        \"haven't\": \"have not\",\n","        \"hasn't\": \"has not\",\n","        \"hadn't\": \"had not\",\n","        \"won't\": \"will not\",\n","        \"wouldn't\": \"would not\",\n","        \"don't\": \"do not\",\n","        \"doesn't\": \"does not\",\n","        \"didn't\": \"did not\",\n","        \"can't\": \"cannot\",\n","        \"couldn't\": \"could not\",\n","        \"shouldn't\": \"should not\",\n","        \"mightn't\": \"might not\",\n","        \"mustn't\": \"must not\",\n","        \"'s\": \" is\",\n","        \"'re\": \" are\",\n","        \"'m\": \" am\",\n","        \"'ll\": \" will\"\n","    }\n","    for contraction, expansion in contractions_map.items():\n","        text = text.replace(contraction,expansion)\n","    return text\n","\n","def replace_digits_with_words(text):\n","    # Map digits to their word representations (0-9 for simplicity)\n","    digit_map = {\n","        '0': 'zero', '1': 'one', '2': 'two', '3': 'three', '4': 'four',\n","        '5': 'five', '6': 'six', '7': 'seven', '8': 'eight', '9': 'nine'\n","    }\n","\n","    # Replace digits with their word representations\n","    for digit, word in digit_map.items():\n","        text = text.replace(digit, word)\n","\n","    return text\n","\n","def remove_special_characters(text):\n","    # Define a set of special characters to remove\n","    special_characters = set(\"!\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~\")\n","\n","    # Remove special characters from the text\n","    cleaned_text = \"\".join(char for char in text if char not in special_characters)\n","    return cleaned_text\n","\n","def to_lower_case(text):\n","    lower_text = \"\"\n","    for char in text:\n","        # Check if character is uppercase\n","        if 'A' <= char <= 'Z':\n","            # Convert uppercase character to lowercase\n","            lower_text += chr(ord(char) + 32)\n","        else:\n","            lower_text += char\n","    return lower_text\n","\n","def remove_urls(text):\n","    # Split text into words\n","    words = text.split()\n","    # Filter out words that do not start with 'http' or 'https'\n","    filtered_words = [word for word in words if not (word.startswith('http://') or word.startswith('https://'))]\n","    # Join the filtered words back into a string\n","    return ' '.join(filtered_words)\n","\n","\n","# Load your DataFrame from 'training.tsv' assuming it contains text data\n","df = pd.read_csv('training.tsv', sep='\\t')\n","\n","# Apply the preprocess function to each element in the DataFrame\n","# df['cleaned_text'] = df['text'].apply(preprocess)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"ee81f666","metadata":{"id":"ee81f666"},"outputs":[],"source":["import emoji\n","def emo(text):\n","  temp=emoji.demojize(text,delimiters=(\" \",\" \"))\n","  temp=temp.replace(\"_\",\"  \")\n","  return temp"]},{"cell_type":"code","execution_count":null,"id":"36b9735d","metadata":{"id":"36b9735d"},"outputs":[],"source":["df['emo']=df[\"text\"].apply(lambda x:emo(x))\n","df['cleaned_text'] = df['emo'].apply(preprocess)"]},{"cell_type":"code","execution_count":null,"id":"9473ff06","metadata":{"id":"9473ff06","outputId":"9df88aba-ac23-4860-f509-6de74644d03d"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet_id</th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>emo</th>\n","      <th>cleaned_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1382343793341575169</td>\n","      <td>@IrvineWelsh I donâ€™t know about you Irvine but...</td>\n","      <td>0</td>\n","      <td>@IrvineWelsh I donâ€™t know about you Irvine but...</td>\n","      <td>irvinewelsh not know irvine keep told covid no...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1377631738692796417</td>\n","      <td>I bet money if i went n took a covid test righ...</td>\n","      <td>0</td>\n","      <td>I bet money if i went n took a covid test righ...</td>\n","      <td>bet money went n took covid test right now imm...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1386448010029240326</td>\n","      <td>@JamesMelville My wife received a POSITIVE Cov...</td>\n","      <td>0</td>\n","      <td>@JamesMelville My wife received a POSITIVE Cov...</td>\n","      <td>jamesmelville wife received positive covid tes...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1361342676340211717</td>\n","      <td>Out of the 180,000+ people who have had the tw...</td>\n","      <td>0</td>\n","      <td>Out of the 180,000+ people who have had the tw...</td>\n","      <td>oneeightzerozerozerozero people two vaccine sh...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1386757983254765569</td>\n","      <td>My whole family is sick af and here I am now i...</td>\n","      <td>0</td>\n","      <td>My whole family is sick af and here I am now i...</td>\n","      <td>whole family sick af here now hospital heart p...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1382001700853125122</td>\n","      <td>@renfrew1962 @PeakePolly @J_Deliciouso I'm not...</td>\n","      <td>0</td>\n","      <td>@renfrew1962 @PeakePolly @J  Deliciouso I'm no...</td>\n","      <td>renfrewoneninesixtwo peakepolly j deliciouso n...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1383272654212272136</td>\n","      <td>Test came back positive, no surprise. I have c...</td>\n","      <td>1</td>\n","      <td>Test came back positive, no surprise. I have c...</td>\n","      <td>test came back positive no surprise covid full...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1374479299047084035</td>\n","      <td>My Pawpaw has been in the hospital a few days....</td>\n","      <td>0</td>\n","      <td>My Pawpaw has been in the hospital a few days....</td>\n","      <td>pawpaw hospital few days got special approval ...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1354020426620547072</td>\n","      <td>@MattHancock 4 people I know had covid and rec...</td>\n","      <td>0</td>\n","      <td>@MattHancock 4 people I know had covid and rec...</td>\n","      <td>matthancock four people know covid recovered e...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1362671045136809985</td>\n","      <td>Iâ€™m going to sound like I have lost my marbles...</td>\n","      <td>1</td>\n","      <td>Iâ€™m going to sound like I have lost my marbles...</td>\n","      <td>going sound like lost marbles not felt well si...</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1373077971658022918</td>\n","      <td>I just tested positive for Covid-19 from two s...</td>\n","      <td>1</td>\n","      <td>I just tested positive for Covid-19 from two s...</td>\n","      <td>just tested positive covidonenine two separate...</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>1373076070312730633</td>\n","      <td>Someone I love very much was diagnosed with co...</td>\n","      <td>0</td>\n","      <td>Someone I love very much was diagnosed with co...</td>\n","      <td>someone love very much diagnosed covid onenine...</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>1331292744489250816</td>\n","      <td>Dear @PeterHotez ,Serious question about Vacci...</td>\n","      <td>0</td>\n","      <td>Dear @PeterHotez ,Serious question about Vacci...</td>\n","      <td>dear peterhotez serious question vaccinein one...</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1379116535726415874</td>\n","      <td>As I was in the ER last night I overheard a co...</td>\n","      <td>1</td>\n","      <td>As I was in the ER last night I overheard a co...</td>\n","      <td>er last night overheard conversation someone w...</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>1357823724192296960</td>\n","      <td>@jrlsilverman @dilleradollar @OregonGovBrown ðŸ’¡...</td>\n","      <td>0</td>\n","      <td>@jrlsilverman @dilleradollar @OregonGovBrown  ...</td>\n","      <td>jrlsilverman dilleradollar oregongovbrown ligh...</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>1376702269991890945</td>\n","      <td>Today: 1 person (after overnight code) in ICU ...</td>\n","      <td>0</td>\n","      <td>Today: 1 person (after overnight code) in ICU ...</td>\n","      <td>today one person overnight code icu wcovid fiv...</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>1377607714524831745</td>\n","      <td>@Asilverlining20 @TVpsychologist @NHSuk Itâ€™s b...</td>\n","      <td>0</td>\n","      <td>@Asilverlining20 @TVpsychologist @NHSuk Itâ€™s b...</td>\n","      <td>asilverliningtwozero tvpsychologist nhsuk year...</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>1388377556097904640</td>\n","      <td>These side effects are CRAZY!!! Got the second...</td>\n","      <td>0</td>\n","      <td>These side effects are CRAZY!!! Got the second...</td>\n","      <td>side effects crazy got second pfizer vaccine t...</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>1377509820425723912</td>\n","      <td>@BethMooreLPM Continuing to #Pray for Healing ...</td>\n","      <td>0</td>\n","      <td>@BethMooreLPM Continuing to #Pray for Healing ...</td>\n","      <td>bethmoorelpm continuing pray healing miracles ...</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>1383382420234280964</td>\n","      <td>@mstranack @GillianMcKeith Just spoke to Hayde...</td>\n","      <td>0</td>\n","      <td>@mstranack @GillianMcKeith Just spoke to Hayde...</td>\n","      <td>mstranack gillianmckeith just spoke hayden mor...</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>1333413081083310081</td>\n","      <td>There are Lies, Damn lies, and Statistics.http...</td>\n","      <td>0</td>\n","      <td>There are Lies, Damn lies, and Statistics.http...</td>\n","      <td>there lies damn lies statisticshttpstcozerovae...</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>1386707720317935617</td>\n","      <td>@basakcoruhUW @nickmmark I think what hurts th...</td>\n","      <td>0</td>\n","      <td>@basakcoruhUW @nickmmark I think what hurts th...</td>\n","      <td>basakcoruhuw nickmmark think hurts most physic...</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>1375292877195120640</td>\n","      <td>@Tempid_ I actually tested positive for covid....</td>\n","      <td>1</td>\n","      <td>@Tempid   I actually tested positive for covid...</td>\n","      <td>tempid actually tested positive covid only sic...</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>1350649856830828546</td>\n","      <td>@IA___09 @leighjoyus @lc5190 @FlatEarthCity It...</td>\n","      <td>0</td>\n","      <td>@IA      09 @leighjoyus @lc5190 @FlatEarthCity...</td>\n","      <td>ia zeronine leighjoyus lcfiveoneninezero flate...</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>1377254105752690696</td>\n","      <td>A year ago, on this date, I made the decision ...</td>\n","      <td>0</td>\n","      <td>A year ago, on this date, I made the decision ...</td>\n","      <td>year ago date made decision bring husband twoz...</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>1383590378712956929</td>\n","      <td>One week back from Daytona, my whole family ge...</td>\n","      <td>1</td>\n","      <td>One week back from Daytona, my whole family ge...</td>\n","      <td>one week back daytona whole family gets really...</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>1388238564220030977</td>\n","      <td>@TheDamaniFelder I still donâ€™t know anyone who...</td>\n","      <td>0</td>\n","      <td>@TheDamaniFelder I still donâ€™t know anyone who...</td>\n","      <td>thedamanifelder still not know anyone died cov...</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>1373218284129157120</td>\n","      <td>@PointCrow Honestly just a text back from her ...</td>\n","      <td>0</td>\n","      <td>@PointCrow Honestly just a text back from her ...</td>\n","      <td>pointcrow honestly just text back telling â€œgoo...</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>1385316180739624972</td>\n","      <td>I have Covid. Yaay... ðŸ™„ðŸ™„ Went to get tested, b...</td>\n","      <td>0</td>\n","      <td>I have Covid. Yaay...  face  with  rolling  ey...</td>\n","      <td>covid yaay face rolling eyes face rolling eyes...</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>1386017989053624320</td>\n","      <td>@AntiLockdownAl2 @Rainbowandsteel Totally ...s...</td>\n","      <td>0</td>\n","      <td>@AntiLockdownAl2 @Rainbowandsteel Totally ...s...</td>\n","      <td>antilockdownaltwo rainbowandsteel totally some...</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>1326482267913515013</td>\n","      <td>I feel like we dont talk about this enough. Ne...</td>\n","      <td>0</td>\n","      <td>I feel like we dont talk about this enough. Ne...</td>\n","      <td>feel like dont talk enough new zealand will ke...</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>1384105411607814147</td>\n","      <td>@JonathanTaylorX @zoeharcombe I don't accept g...</td>\n","      <td>0</td>\n","      <td>@JonathanTaylorX @zoeharcombe I don't accept g...</td>\n","      <td>jonathantaylorx zoeharcombe not accept governm...</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>1378083348334178307</td>\n","      <td>One of the nurses I've been interviewing for a...</td>\n","      <td>0</td>\n","      <td>One of the nurses I've been interviewing for a...</td>\n","      <td>one nurses ive interviewing year just texted s...</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>1384541171062611970</td>\n","      <td>@chrisforgione8 @PlauDD @PGATOURComms What an ...</td>\n","      <td>0</td>\n","      <td>@chrisforgione8 @PlauDD @PGATOURComms What an ...</td>\n","      <td>chrisforgioneeight plaudd pgatourcomms odd thi...</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>1383184499534663683</td>\n","      <td>@sammylynn_ Yes super weird, I mean Iâ€™ve had o...</td>\n","      <td>0</td>\n","      <td>@sammylynn   Yes super weird, I mean Iâ€™ve had ...</td>\n","      <td>sammylynn yes super weird mean ive threezero e...</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>1386544834308042752</td>\n","      <td>@yxung_i @mq1ie @theCooingDove @teatuahere @al...</td>\n","      <td>0</td>\n","      <td>@yxung  i @mq1ie @theCooingDove @teatuahere @a...</td>\n","      <td>yxung mqoneie thecooingdove teatuahere alexavr...</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>1387968398127206401</td>\n","      <td>@Foxyzilla Sneezing and the runny nose are pre...</td>\n","      <td>0</td>\n","      <td>@Foxyzilla Sneezing and the runny nose are pre...</td>\n","      <td>foxyzilla sneezing runny nose pretty positive ...</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>1303158275106639872</td>\n","      <td>Iâ€™m going to get a vaccine in like December an...</td>\n","      <td>0</td>\n","      <td>Iâ€™m going to get a vaccine in like December an...</td>\n","      <td>going get vaccine like december think dodged l...</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>1385398326863044612</td>\n","      <td>@lenfantbon @jacobjamesrich @robbysoave Iâ€™m ch...</td>\n","      <td>0</td>\n","      <td>@lenfantbon @jacobjamesrich @robbysoave Iâ€™m ch...</td>\n","      <td>lenfantbon jacobjamesrich robbysoave cherry pi...</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>1334531743274192896</td>\n","      <td>After spending 12 days in the hospital (non-CO...</td>\n","      <td>0</td>\n","      <td>After spending 12 days in the hospital (non-CO...</td>\n","      <td>spending onetwo days hospital noncovid can con...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               tweet_id                                               text  \\\n","0   1382343793341575169  @IrvineWelsh I donâ€™t know about you Irvine but...   \n","1   1377631738692796417  I bet money if i went n took a covid test righ...   \n","2   1386448010029240326  @JamesMelville My wife received a POSITIVE Cov...   \n","3   1361342676340211717  Out of the 180,000+ people who have had the tw...   \n","4   1386757983254765569  My whole family is sick af and here I am now i...   \n","5   1382001700853125122  @renfrew1962 @PeakePolly @J_Deliciouso I'm not...   \n","6   1383272654212272136  Test came back positive, no surprise. I have c...   \n","7   1374479299047084035  My Pawpaw has been in the hospital a few days....   \n","8   1354020426620547072  @MattHancock 4 people I know had covid and rec...   \n","9   1362671045136809985  Iâ€™m going to sound like I have lost my marbles...   \n","10  1373077971658022918  I just tested positive for Covid-19 from two s...   \n","11  1373076070312730633  Someone I love very much was diagnosed with co...   \n","12  1331292744489250816  Dear @PeterHotez ,Serious question about Vacci...   \n","13  1379116535726415874  As I was in the ER last night I overheard a co...   \n","14  1357823724192296960  @jrlsilverman @dilleradollar @OregonGovBrown ðŸ’¡...   \n","15  1376702269991890945  Today: 1 person (after overnight code) in ICU ...   \n","16  1377607714524831745  @Asilverlining20 @TVpsychologist @NHSuk Itâ€™s b...   \n","17  1388377556097904640  These side effects are CRAZY!!! Got the second...   \n","18  1377509820425723912  @BethMooreLPM Continuing to #Pray for Healing ...   \n","19  1383382420234280964  @mstranack @GillianMcKeith Just spoke to Hayde...   \n","20  1333413081083310081  There are Lies, Damn lies, and Statistics.http...   \n","21  1386707720317935617  @basakcoruhUW @nickmmark I think what hurts th...   \n","22  1375292877195120640  @Tempid_ I actually tested positive for covid....   \n","23  1350649856830828546  @IA___09 @leighjoyus @lc5190 @FlatEarthCity It...   \n","24  1377254105752690696  A year ago, on this date, I made the decision ...   \n","25  1383590378712956929  One week back from Daytona, my whole family ge...   \n","26  1388238564220030977  @TheDamaniFelder I still donâ€™t know anyone who...   \n","27  1373218284129157120  @PointCrow Honestly just a text back from her ...   \n","28  1385316180739624972  I have Covid. Yaay... ðŸ™„ðŸ™„ Went to get tested, b...   \n","29  1386017989053624320  @AntiLockdownAl2 @Rainbowandsteel Totally ...s...   \n","30  1326482267913515013  I feel like we dont talk about this enough. Ne...   \n","31  1384105411607814147  @JonathanTaylorX @zoeharcombe I don't accept g...   \n","32  1378083348334178307  One of the nurses I've been interviewing for a...   \n","33  1384541171062611970  @chrisforgione8 @PlauDD @PGATOURComms What an ...   \n","34  1383184499534663683  @sammylynn_ Yes super weird, I mean Iâ€™ve had o...   \n","35  1386544834308042752  @yxung_i @mq1ie @theCooingDove @teatuahere @al...   \n","36  1387968398127206401  @Foxyzilla Sneezing and the runny nose are pre...   \n","37  1303158275106639872  Iâ€™m going to get a vaccine in like December an...   \n","38  1385398326863044612  @lenfantbon @jacobjamesrich @robbysoave Iâ€™m ch...   \n","39  1334531743274192896  After spending 12 days in the hospital (non-CO...   \n","\n","    label                                                emo  \\\n","0       0  @IrvineWelsh I donâ€™t know about you Irvine but...   \n","1       0  I bet money if i went n took a covid test righ...   \n","2       0  @JamesMelville My wife received a POSITIVE Cov...   \n","3       0  Out of the 180,000+ people who have had the tw...   \n","4       0  My whole family is sick af and here I am now i...   \n","5       0  @renfrew1962 @PeakePolly @J  Deliciouso I'm no...   \n","6       1  Test came back positive, no surprise. I have c...   \n","7       0  My Pawpaw has been in the hospital a few days....   \n","8       0  @MattHancock 4 people I know had covid and rec...   \n","9       1  Iâ€™m going to sound like I have lost my marbles...   \n","10      1  I just tested positive for Covid-19 from two s...   \n","11      0  Someone I love very much was diagnosed with co...   \n","12      0  Dear @PeterHotez ,Serious question about Vacci...   \n","13      1  As I was in the ER last night I overheard a co...   \n","14      0  @jrlsilverman @dilleradollar @OregonGovBrown  ...   \n","15      0  Today: 1 person (after overnight code) in ICU ...   \n","16      0  @Asilverlining20 @TVpsychologist @NHSuk Itâ€™s b...   \n","17      0  These side effects are CRAZY!!! Got the second...   \n","18      0  @BethMooreLPM Continuing to #Pray for Healing ...   \n","19      0  @mstranack @GillianMcKeith Just spoke to Hayde...   \n","20      0  There are Lies, Damn lies, and Statistics.http...   \n","21      0  @basakcoruhUW @nickmmark I think what hurts th...   \n","22      1  @Tempid   I actually tested positive for covid...   \n","23      0  @IA      09 @leighjoyus @lc5190 @FlatEarthCity...   \n","24      0  A year ago, on this date, I made the decision ...   \n","25      1  One week back from Daytona, my whole family ge...   \n","26      0  @TheDamaniFelder I still donâ€™t know anyone who...   \n","27      0  @PointCrow Honestly just a text back from her ...   \n","28      0  I have Covid. Yaay...  face  with  rolling  ey...   \n","29      0  @AntiLockdownAl2 @Rainbowandsteel Totally ...s...   \n","30      0  I feel like we dont talk about this enough. Ne...   \n","31      0  @JonathanTaylorX @zoeharcombe I don't accept g...   \n","32      0  One of the nurses I've been interviewing for a...   \n","33      0  @chrisforgione8 @PlauDD @PGATOURComms What an ...   \n","34      0  @sammylynn   Yes super weird, I mean Iâ€™ve had ...   \n","35      0  @yxung  i @mq1ie @theCooingDove @teatuahere @a...   \n","36      0  @Foxyzilla Sneezing and the runny nose are pre...   \n","37      0  Iâ€™m going to get a vaccine in like December an...   \n","38      0  @lenfantbon @jacobjamesrich @robbysoave Iâ€™m ch...   \n","39      0  After spending 12 days in the hospital (non-CO...   \n","\n","                                         cleaned_text  \n","0   irvinewelsh not know irvine keep told covid no...  \n","1   bet money went n took covid test right now imm...  \n","2   jamesmelville wife received positive covid tes...  \n","3   oneeightzerozerozerozero people two vaccine sh...  \n","4   whole family sick af here now hospital heart p...  \n","5   renfrewoneninesixtwo peakepolly j deliciouso n...  \n","6   test came back positive no surprise covid full...  \n","7   pawpaw hospital few days got special approval ...  \n","8   matthancock four people know covid recovered e...  \n","9   going sound like lost marbles not felt well si...  \n","10  just tested positive covidonenine two separate...  \n","11  someone love very much diagnosed covid onenine...  \n","12  dear peterhotez serious question vaccinein one...  \n","13  er last night overheard conversation someone w...  \n","14  jrlsilverman dilleradollar oregongovbrown ligh...  \n","15  today one person overnight code icu wcovid fiv...  \n","16  asilverliningtwozero tvpsychologist nhsuk year...  \n","17  side effects crazy got second pfizer vaccine t...  \n","18  bethmoorelpm continuing pray healing miracles ...  \n","19  mstranack gillianmckeith just spoke hayden mor...  \n","20  there lies damn lies statisticshttpstcozerovae...  \n","21  basakcoruhuw nickmmark think hurts most physic...  \n","22  tempid actually tested positive covid only sic...  \n","23  ia zeronine leighjoyus lcfiveoneninezero flate...  \n","24  year ago date made decision bring husband twoz...  \n","25  one week back daytona whole family gets really...  \n","26  thedamanifelder still not know anyone died cov...  \n","27  pointcrow honestly just text back telling â€œgoo...  \n","28  covid yaay face rolling eyes face rolling eyes...  \n","29  antilockdownaltwo rainbowandsteel totally some...  \n","30  feel like dont talk enough new zealand will ke...  \n","31  jonathantaylorx zoeharcombe not accept governm...  \n","32  one nurses ive interviewing year just texted s...  \n","33  chrisforgioneeight plaudd pgatourcomms odd thi...  \n","34  sammylynn yes super weird mean ive threezero e...  \n","35  yxung mqoneie thecooingdove teatuahere alexavr...  \n","36  foxyzilla sneezing runny nose pretty positive ...  \n","37  going get vaccine like december think dodged l...  \n","38  lenfantbon jacobjamesrich robbysoave cherry pi...  \n","39  spending onetwo days hospital noncovid can con...  "]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["df.head(40)"]},{"cell_type":"code","execution_count":null,"id":"c0964c19","metadata":{"id":"c0964c19","outputId":"2406c865-5ff0-41a5-8439-2a93b0dd9358"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cleaned Text: not seen dont here cannot not not not\n"]}],"source":["sample_text = \"I haven't seen it, but don't here can't wasn't weren't haven't\"\n","cleaned_text = preprocess(sample_text)\n","print(\"Cleaned Text:\", cleaned_text)"]},{"cell_type":"code","execution_count":null,"id":"2977f27e","metadata":{"id":"2977f27e","outputId":"c1f9561d-2f26-485a-dc9b-3ba4bda4f69a"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'contraction_list'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9644/3456016862.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimport_ipynb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcontraction_list\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontractions_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m\"can't,don't,shouldn't\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcontraction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpansion\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcontractions_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontraction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpansion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'contraction_list'"]}],"source":["import import_ipynb\n","from contraction_list import contractions_list\n","text= \"can't,don't,shouldn't\"\n","for contraction, expansion in contractions_map.items():\n","    text = text.replace(contraction, expansion)\n","print(text)"]},{"cell_type":"code","execution_count":null,"id":"3ebbecfa","metadata":{"id":"3ebbecfa"},"outputs":[],"source":["import pandas as pd\n","\n","def preprocess(text):\n","    # Convert text to lowercase\n","    text = custom_lower(text)  # Convert to string and then lowercase\n","    text = replace_digits_with_words(text)\n","    text = remove_urls(text)\n","    text = remove_special_characters(text)\n","     #remove contraction\n","    text = text.replace(\"â€™\", \"'\") #replace curly aposrophe with straight aposrophe\n","    text=contraction(text)\n","\n","    # Tokenize the text manually (splitting by whitespace)\n","    tokens = text.split()\n","    english_stopwords = set([\n","        \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\",\n","        \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\",\n","        \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\",\n","        \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\",\n","        \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\",\n","        \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\",\n","        \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\",\n","        \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\",\n","        \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\",\n","        \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\"\n","    ])\n","    tokens = [token for token in tokens if token not in english_stopwords]\n","\n","    # Join tokens back into a string\n","    processed_text = \" \".join(tokens)\n","    return processed_text\n","\n","def contraction(text):\n","    contractions_map = {\n","        \"ain't\": \"am not / is not / are not / has not / have not\",\n","        \"aren't\": \"are not\",\n","        \"can't\": \"cannot\",\n","        \"can't've\": \"cannot have\",\n","        \"'cause\": \"because\",\n","        \"could've\": \"could have\",\n","        \"couldn't\": \"could not\",\n","        \"couldn't've\": \"could not have\",\n","        \"didn't\": \"did not\",\n","        \"doesn't\": \"does not\",\n","        \"don't\": \"do not\",\n","        \"hadn't\": \"had not\",\n","        \"hadn't've\": \"had not have\",\n","        \"hasn't\": \"has not\",\n","        \"haven't\": \"have not\",\n","        \"he'd\": \"he would / he had\",\n","        \"he'd've\": \"he would have\",\n","        \"he'll\": \"he will\",\n","        \"he'll've\": \"he will have\",\n","        \"he's\": \"he is / he has\",\n","        \"how'd\": \"how did\",\n","        \"how'd'y\": \"how do you\",\n","        \"how'll\": \"how will\",\n","        \"how's\": \"how is / how has / how does\",\n","        \"i'd\": \"i would / I had\",\n","        \"i'd've\": \"i would have\",\n","        \"i'll\": \"i will\",\n","        \"i'll've\": \"i will have\",\n","        \"i'm\": \"i am\",\n","        \"i've\": \"i have\",\n","        \"isn't\": \"is not\",\n","        \"it'd\": \"it would / it had\",\n","        \"it'd've\": \"it would have\",\n","        \"it'll\": \"it will\",\n","        \"it'll've\": \"it will have\",\n","        \"it's\": \"it is / it has\",\n","        \"let's\": \"let us\",\n","        \"ma'am\": \"madam\",\n","        \"mayn't\": \"may not\",\n","        \"might've\": \"might have\",\n","        \"mightn't\": \"might not\",\n","        \"mightn't've\": \"might not have\",\n","        \"must've\": \"must have\",\n","        \"mustn't\": \"must not\",\n","        \"mustn't've\": \"must not have\",\n","        \"needn't\": \"need not\",\n","        \"needn't've\": \"need not have\",\n","        \"o'clock\": \"of the clock\",\n","        \"oughtn't\": \"ought not\",\n","        \"oughtn't've\": \"ought not have\",\n","        \"shan't\": \"shall not\",\n","        \"sha'n't\": \"shall not\",\n","        \"shan't've\": \"shall not have\",\n","        \"she'd\": \"she would / she had\",\n","        \"she'd've\": \"she would have\",\n","        \"she'll\": \"she will\",\n","        \"she'll've\": \"she will have\",\n","        \"she's\": \"she is / she has\",\n","        \"should've\": \"should have\",\n","        \"shouldn't\": \"should not\",\n","        \"shouldn't've\": \"should not have\",\n","        \"so've\": \"so have\",\n","        \"so's\": \"so is / so has\",\n","        \"that'd\": \"that would / that had\",\n","        \"that'd've\": \"that would have\",\n","        \"that's\": \"that is / that has\",\n","        \"there'd\": \"there would / there had\",\n","        \"there'd've\": \"there would have\",\n","        \"there's\": \"there is / there has\",\n","        \"they'd\": \"they would / they had\",\n","        \"they'd've\": \"they would have\",\n","        \"they'll\": \"they will\",\n","        \"they'll've\": \"they will have\",\n","        \"they're\": \"they are\",\n","        \"they've\": \"they have\",\n","        \"to've\": \"to have\",\n","        \"wasn't\": \"was not\",\n","        \"we'd\": \"we would / we had\",\n","        \"we'd've\": \"we would have\",\n","        \"we'll\": \"we will\",\n","        \"we'll've\": \"we will have\",\n","        \"we're\": \"we are\",\n","        \"we've\": \"we have\",\n","        \"weren't\": \"were not\",\n","        \"what'll\": \"what will\",\n","        \"what'll've\": \"what will have\",\n","        \"what're\": \"what are\",\n","        \"what's\": \"what is / what has\",\n","        \"what've\": \"what have\",\n","        \"when's\": \"when is / when has\",\n","        \"when've\": \"when have\",\n","        \"where'd\": \"where did\",\n","        \"where's\": \"where is / where has\",\n","        \"where've\": \"where have\",\n","        \"who'll\": \"who will\",\n","        \"who'll've\": \"who will have\",\n","        \"who's\": \"who is / who has\",\n","        \"who've\": \"who have\",\n","        \"why's\": \"why is / why has\",\n","        \"why've\": \"why have\",\n","        \"will've\": \"will have\",\n","        \"won't\": \"will not\",\n","        \"won't've\": \"will not have\",\n","        \"would've\": \"would have\",\n","        \"wouldn't\": \"would not\",\n","        \"wouldn't've\": \"would not have\",\n","        \"y'all\": \"you all\",\n","        \"y'all'd\": \"you all would\",\n","        \"y'all'd've\": \"you all would have\",\n","        \"y'all're\": \"you all are\",\n","        \"y'all've\": \"you all have\",\n","        \"you'd\": \"you would / you had\",\n","        \"you'd've\": \"you would have\",\n","        \"you'll\": \"you will\",\n","        \"you'll've\": \"you will have\",\n","        \"you're\": \"you are\",\n","        \"you've\": \"you have\"\n","    }\n","    for contraction, expansion in contractions_map.items():\n","        text = text.replace(contraction, expansion)\n","        return text\n","\n","def replace_digits_with_words(text):\n","    # Map digits to their word representations (0-9 for simplicity)\n","    digit_map = {\n","        '0': 'zero', '1': 'one', '2': 'two', '3': 'three', '4': 'four',\n","        '5': 'five', '6': 'six', '7': 'seven', '8': 'eight', '9': 'nine'\n","    }\n","\n","    # Replace digits with their word representations\n","    for digit, word in digit_map.items():\n","        text = text.replace(digit, word)\n","\n","    return text\n","\n","def remove_special_characters(text):\n","    # Define a set of special characters to remove\n","    special_characters = set(\"!\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~\")\n","\n","    # Remove special characters from the text\n","    cleaned_text = \"\".join(char for char in text if char not in special_characters)\n","\n","    return cleaned_text\n","def custom_lower(text):\n","    # Convert text to lowercase using custom implementation (ASCII manipulation)\n","    lower_text = \"\"\n","    for char in text:\n","        if 'A' <= char <= 'Z':  # Check if the character is uppercase\n","            lower_char = chr(ord(char) + 32)  # Convert to lowercase using ASCII manipulation\n","        else:\n","            lower_char = char  # Keep the character unchanged if not uppercase\n","        lower_text += lower_char  # Append the lowercase (or unchanged) character\n","    return lower_text\n","def remove_urls(text):\n","    # Split text into words\n","    words = text.split()\n","    # Filter out words that do not start with 'http' or 'https'\n","    filtered_words = [word for word in words if not (word.startswith('http://') or word.startswith('https://'))]\n","    # Join the filtered words back into a string\n","    return ' '.join(filtered_words)\n","df = pd.read_csv('training.tsv', sep='\\t')"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}